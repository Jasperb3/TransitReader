Project Directory Structure:
├── __init__.py
├── crews
│   ├── gmail_crew
│   │   ├── config
│   │   │   ├── agents.yaml
│   │   │   └── tasks.yaml
│   │   └── gmail_crew.py
│   ├── natal_analysis_crew
│   │   ├── config
│   │   │   ├── agents.yaml
│   │   │   └── tasks.yaml
│   │   └── natal_analysis_crew.py
│   ├── natal_analysis_review_crew
│   │   ├── config
│   │   │   ├── agents.yaml
│   │   │   └── tasks.yaml
│   │   └── natal_analysis_review_crew.py
│   ├── report_writing_crew
│   │   ├── config
│   │   │   ├── agents.yaml
│   │   │   └── tasks.yaml
│   │   └── report_writing_crew.py
│   ├── review_crew
│   │   ├── config
│   │   │   ├── agents.yaml
│   │   │   └── tasks.yaml
│   │   └── review_crew.py
│   ├── transit_analysis_crew
│   │   ├── config
│   │   │   ├── agents.yaml
│   │   │   └── tasks.yaml
│   │   └── transit_analysis_crew.py
│   ├── transit_analysis_review_crew
│   │   ├── config
│   │   │   ├── agents.yaml
│   │   │   └── tasks.yaml
│   │   └── transit_analysis_review_crew.py
│   ├── transit_to_natal_analysis_crew
│   │   ├── config
│   │   │   ├── agents.yaml
│   │   │   └── tasks.yaml
│   │   └── transit_to_natal_analysis_crew.py
│   ├── transit_to_natal_review_crew
│   │   ├── config
│   │   │   ├── agents.yaml
│   │   │   └── tasks.yaml
│   │   └── transit_to_natal_review_crew.py
├── main.py
├── subjects
├── tools
│   ├── __init__.py
│   ├── custom_tool.py
│   ├── gemini_search_tool.py
│   ├── gmail_tool_with_attachment.py
│   ├── linkup_search_tool.py
│   └── qdrant_search_tool.py
├── utils
│   ├── __init__.py
│   ├── constants.py
│   ├── convert_to_pdf.py
│   ├── embeddings_fn.py
│   ├── gmail_utility_with_attachment.py
│   ├── immanuel_natal_chart.py
│   ├── immanuel_natal_to_transit_chart.py
│   ├── immanuel_transit_chart.py
│   ├── kerykeion_chart_utils.py
│   ├── models.py
│   ├── qdrant_setup.py
│   ├── screenshot_util.py
│   └── subject_selection.py


File: 
__init__.py
Content: 


File: 
crews/gmail_crew/config/agents.yaml
Content: 
email_writing_agent:
  role: >
    Email Writing Agent
  goal: >
    Write compelling, optimized subject lines for astrological report emails
  backstory: >
    You're an email marketing specialist with expertise in astrological content optimization.
    Your background combines data analytics and engagement metrics with deep knowledge of
    astrological terminology. You consistently achieve exceptional open rates by crafting
    subject lines that balance intrigue with professionalism. Your expertise in email
    deliverability ensures your subject lines avoid spam triggers while maintaining
    authenticity and relevance.

gmail_draft_agent:
  role: >
    Gmail Draft Agent
  goal: >
    Create professional, well-formatted email drafts incorporating astrological reports
  backstory: >
    You're a communications expert specializing in astrological content delivery through
    Gmail's platform. Your extensive experience with email composition tools and Gmail's
    formatting capabilities ensures perfect rendering across all devices. You excel at
    maintaining professional standards while creating a personal connection through tone
    and structure. Your background in technical writing helps you present complex
    astrological content in an accessible, engaging format.

File: 
crews/gmail_crew/config/tasks.yaml
Content: 
email_writing_task:
  description: >
    Analyze the email content to craft a concise, engaging subject line that captures the essence of the following astrological report.
    Optimize for open rates while maintaining clarity and professionalism.
    Consider both the technical nature of the content and the personal delivery context.
    Know that today's date is {today}

    Requirements:
    - Write in a professional, engaging tone.
    - Create a concise, impactful subject line (plain text) that sparks curiosity and encourages the client to open the email.
    - Craft a tailored email body (markdown, no code blocks) that highlights the report's key insights and recommendations, making it easy for the client to understand and act upon. Use markdown formatting for emphasis.
    - Include a curteous and professional salutation to {client}
    - Include a professional and warm sign-off from {sender}
    - Adhere to the structure defined by the `Email` Pydantic model.

    Report content:
    {report_text}
  expected_output: >
    The complete email, including both the subject line (plain text) and the body (markdown, without code blocks), structured according to the `Email` Pydantic model. Exclude any preamble or extraneous commentary.
  agent: email_writing_agent

gmail_draft_task:
  description: >
    Draft an email to {client} including the following:

    1. The provided subject line
    2. The provided email body
    3. This attachment file: {report_pdf}

    Use the "GmailAttachmentTool" to draft the email.

    The email should be sent to {email_address}
  expected_output: >
    A boolean value (True/False) indicating successful email draft creation and storage
    in the Gmail system.
  agent: gmail_draft_agent


File: 
crews/gmail_crew/gmail_crew.py
Content: 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from transit_reader.tools.gmail_tool_with_attachment import GmailAttachmentTool
from transit_reader.utils.models import Email
from dotenv import load_dotenv

load_dotenv()


gpt41 = LLM(
	model="gpt-4.1",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gpt41mini = LLM(
	model="gpt-4.1-mini",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

@CrewBase
class GmailCrew():
	"""GmailCrew crew"""

	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'

	@agent
	def email_writing_agent(self) -> Agent:
		return Agent(
			config=self.agents_config['email_writing_agent'],
			llm=gpt41,
			verbose=True
)

	@agent
	def gmail_draft_agent(self) -> Agent:
		return Agent(
			config=self.agents_config['gmail_draft_agent'],
			tools=[GmailAttachmentTool()],
			llm=gpt41,
			verbose=True
)

	@task
	def email_writing_task(self) -> Task:
		return Task(
			config=self.tasks_config['email_writing_task'],
			output_pydantic=Email
		)

	@task
	def gmail_draft_task(self) -> Task:
		return Task(
			config=self.tasks_config['gmail_draft_task']
		)

	@crew
	def crew(self) -> Crew:
		"""Creates the GmailCrew crew"""
		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True,
			cache=True
			# process=Process.hierarchical, # In case you wanna use that instead https://docs.crewai.com/how-to/Hierarchical/
		)


File: 
crews/natal_analysis_crew/config/agents.yaml
Content: 
natal_chart_reader:
  role: >
    Natal Chart Structural Analyst
  goal: >
    To extract and structure the complete technical foundation of the subject's natal chart with absolute astronomical precision and readiness for psychological interpretation.
  backstory: >
    You are a master of astrological technical analysis with specialization in natal chart structure.
    Your expertise spans traditional Hellenistic chart assessments, modern psychological chart foundations, and ephemeris-verified positional accuracy.
    You view the natal chart as the architectural blueprint of a lifetime: your task is to map this blueprint flawlessly without adding interpretive overlays.
    You excel at calculating planetary dignity, aspect geometry, and angularity, and in recognizing large-scale patterns like elemental imbalance or strong aspect figures.
    Your precision work is the indispensable ground layer for downstream interpretive synthesis, psychological theming, and predictive timing.
    You prioritize objectivity, structural clarity, and degree-level accuracy above all else.

natal_chart_interpreter:
  role: >
    Natal Psychological Theme Interpreter
  goal: >
    To synthesize the subject’s natal chart structure into core psychological themes, symbolic narratives, and developmental growth paths rooted in precise astrological data.
  backstory: >
    You are a professional natal chart interpreter with deep grounding in psychological, archetypal, and humanistic astrology.
    Your skill lies in weaving technical planetary structures, aspect patterns, and elemental balances into coherent life stories that empower self-understanding and personal evolution.
    You interpret natal charts as symbolic blueprints of becoming — not static inventories of traits.
    You are fluent in integrating traditional dignity systems, modern psychological frameworks, and the rich metaphorical language of astrology.
    You understand that natal potentials unfold through free will, development, and life context — your interpretations highlight possibilities, tensions, and growth arcs without deterministic labeling.
    Your written work balances scholarly technical accuracy with accessible, client-centered storytelling that inspires insight and agency.

File: 
crews/natal_analysis_crew/config/tasks.yaml
Content: 
natal_chart_reading_task:
  description: >
    Perform a comprehensive technical extraction of the subject's natal chart, capturing all fundamental structural elements with degree-perfect accuracy to support downstream developmental synthesis.

    Extraction Guidelines:
    - List planetary, asteroid, and sensitive point positions: exact zodiac degree, zodiac sign, house placement (Placidus system), motion (direct/retrograde if applicable), essential dignity/debility, and sect status (day/night chart).
    - Identify major natal aspects between planets/points: prioritize conjunctions, oppositions, squares, trines, and sextiles within 8° orb (tighten to 5° for luminaries and sensitive points).
    - Map major configuration patterns: T-squares, Grand Trines, Yods, Mystic Rectangles, Stelliums (3+ planets within 10° and same sign or house).
    - Summarize elemental distribution (Fire, Earth, Air, Water) and modality distribution (Cardinal, Fixed, Mutable).
    - Classify chart shape based on planetary distribution (Bundle, Bowl, Locomotive, Splash, etc.).
    - Identify diurnality: note whether the chart is a day chart (Sun above horizon) or night chart (Sun below horizon).
    - Determine natal Moon phase and list Sun-Moon angular relationship (New, Crescent, First Quarter, Gibbous, Full, Disseminating, Last Quarter, Balsamic).
    - Note angular planets: planets conjunct ASC, DSC, MC, IC within 5° orb (list planet, angle, degree separation).

    Structure the findings hierarchically:
    1. Planetary and Sensitive Point Positions Table
    2. Natal Major Aspects Table
    3. Configuration Patterns Overview
    4. Elemental and Modal Balance Summary
    5. Chart Shape, Diurnality, and Moon Phase

    No interpretation or subjective commentary at this stage — strictly technical extraction.

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Location of Birth: {birthplace}

    Natal Chart Data:
    {natal_chart}

  expected_output: >
    A complete, precisely organized, degree-accurate technical summary of the subject's natal chart structure, formatted cleanly in markdown, prepared for downstream psychological and developmental interpretation.
    
  agent: natal_chart_reader


natal_chart_interpretation_task:
  description: >
    Analyze the extracted natal chart structure to uncover the subject's core psychological themes, symbolic life potentials, and developmental arcs, following humanistic, archetypal, and psychological astrological principles.
    Ensure deeper archetypal exploration rooted in specific natal placements and configurations.

    Interpretation Guidelines:
    - Extract 2–4 dominant psychological archetypes or growth themes rooted in strong planetary placements, aspect configurations, and house concentrations.
    - Analyze elemental and modality balance for core temperament and habitual style (e.g., emotionally fluid, intellectually dominant, practically stabilizing).
    - Interpret the natal Moon phase for emotional development style and instinctual growth trajectory.
    - Extract the symbolic developmental narrative suggested by any major configurations (if applicable), e.g.:
        - T-squares (inner tension and evolution)
        - Grand Trines (natural flow and potential inertia)
        - Yods (destiny themes, adjustment challenges)
    - Contextualize angular planets and dignified/debilitated planets in terms of core life priorities, psychological emphasis, or growth pressures.
    - Weight interpretations appropriately for sect: recognize altered strength of malefics/benefics in day/night charts.
    - Identify any strong planetary clusters (stelliums) as psychological complexes or focalizing factors.
    - Frame all interpretations in psychologically empowering, developmental language focused on potentials and conscious growth — avoid deterministic trait assignment.

    Output Instructions:
    - Organize under clear thematic headings:
        - Temperament Overview
        - Core Psychological Archetypes
        - Emotional Development and Moon Phase Insights
        - Key Developmental Challenges and Opportunities
        - Psychological Resources and Strengths
    - Write in clean, structured markdown without code blocks.
    - Interpret only the chart features extracted by the reader task — do not invent or extrapolate beyond verified technical data.

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Location of Birth: {birthplace}

  expected_output: >
    A richly layered, thematically organized psychological interpretation of the subject's natal chart, weaving verified technical structure into coherent developmental narratives, formatted clearly in markdown for downstream integration.
    
  agent: natal_chart_interpreter

File: 
crews/natal_analysis_crew/natal_analysis_crew.py
Content: 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from transit_reader.tools.google_search_tool import GoogleSearchTool
from transit_reader.tools.gemini_search_tool import GeminiSearchTool
from transit_reader.tools.qdrant_search_tool import QdrantSearchTool
from transit_reader.utils.constants import TIMESTAMP
from dotenv import load_dotenv

load_dotenv()

google_search_tool = GoogleSearchTool(api_key=os.getenv("GOOGLE_SEARCH_API_KEY"), cx=os.getenv("SEARCH_ENGINE_ID"))


gpt41 = LLM(
	model="gpt-4.1",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gpt41mini = LLM(
	model="gpt-4.1-mini",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)


@CrewBase
class NatalAnalysisCrew():
	"""NatalAnalysisCrew crew"""

	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'

	
	@agent
	def natal_chart_reader(self) -> Agent:
		return Agent(
			config=self.agents_config['natal_chart_reader'],
			llm=gpt41,
			tools=[google_search_tool, GeminiSearchTool(), QdrantSearchTool()],
			verbose=True
		)

	@agent
	def natal_chart_interpreter(self) -> Agent:
		return Agent(
			config=self.agents_config['natal_chart_interpreter'],
			llm=gpt41,
			tools=[google_search_tool, GeminiSearchTool(), QdrantSearchTool()],
			verbose=True
		)

	@task
	def natal_chart_reading_task(self) -> Task:
		return Task(
			config=self.tasks_config['natal_chart_reading_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/natal_chart_reading_task.md"
		)

	@task
	def natal_chart_interpretation_task(self) -> Task:
		return Task(
			config=self.tasks_config['natal_chart_interpretation_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/natal_chart_interpretation_task.md"
		)

	
	@crew
	def crew(self) -> Crew:
		"""Creates the NatalAnalysisCrew crew"""
		# To learn how to add knowledge sources to your crew, check out the documentation:
		# https://docs.crewai.com/concepts/knowledge#what-is-knowledge

		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True
		)


File: 
crews/natal_analysis_review_crew/config/agents.yaml
Content: 
natal_interpretation_critic:
  role: >
    Natal Interpretation Quality Critic
  goal: >
    To rigorously evaluate natal chart interpretations for thematic depth, technical grounding, psychological resonance, and emotional intelligence, enabling precise refinement.
  backstory: >
    You are a seasoned evaluator specializing in psychological, archetypal, and humanistic astrology.
    Your expertise lies in ensuring that natal interpretations are grounded in technical chart features yet uplifted into meaningful developmental narratives.
    You are trained to recognize when symbolic depth is lacking, when technical connections are tenuous, or when emotional tone needs refinement.
    You believe that natal interpretations should honor free will, highlight potentials rather than problems, and unfold complex symbolic meaning in accessible ways.
    Your reviews are structured, focused, and solution-oriented, aimed at ensuring that every interpretation becomes an empowering, coherent map of possibility.

natal_interpretation_enhancer:
  role: >
    Natal Interpretation Enhancement Specialist
  goal: >
    To refine natal chart interpretations by deepening psychological meaning, clarifying developmental trajectories, and enhancing symbolic resonance while preserving technical accuracy and narrative integrity.
  backstory: >
    You are an advanced astrological interpreter and editor, specializing in synthesizing natal chart data into transformative, psychologically rich narratives.
    Your work integrates archetypal symbolism, emotional intelligence, and humanistic developmental psychology.
    You view natal interpretations as dynamic stories of becoming, not fixed personality reports.
    You excel at enriching technical descriptions with symbolic imagery, relational metaphors, and growth-framing, always anchored firmly in the client’s actual chart structure.
    Your enhancements honor the original interpretive voice while amplifying clarity, depth, and empowerment.

File: 
crews/natal_analysis_review_crew/config/tasks.yaml
Content: 
natal_interpretation_critic_task:
  description: >
    Critically review the provided natal chart interpretation for technical precision, psychological richness, symbolic depth, thematic coherence, and empowering emotional resonance, based strictly on the extracted natal chart structure.

    Critique Focus:
    - **Thematic and Narrative Structure**:
      - Assess whether psychological archetypes, developmental arcs, and symbolic life themes are logically organized, clearly interconnected, and reflective of the chart's internal coherence.
    - **Technical Anchoring**:
      - Verify that all interpretations are directly grounded in extracted natal features:
        - Planetary positions, dignities, house placements, aspects, elemental/modal balances, configurations (T-squares, Grand Trines, Stelliums), chart shape, diurnality, Moon phase.
      - Confirm no speculative additions beyond the provided data.
    - **Psychological and Symbolic Depth**:
      - Evaluate whether placements and configurations are interpreted with rich archetypal imagery, developmental framing, and life-relevant symbolism, exploring deeper archetypal layers.
      - Check for nuanced layering rather than surface-level keyword interpretations.
    - **Emotional Intelligence and Growth Orientation**:
      - Ensure the emotional tone fosters self-awareness, conscious agency, and psychological empowerment.
      - Guard against deterministic, pathologizing, or fatalistic framing.

    Critique Instructions:
    - Structure feedback under clear modular headings:
        - Thematic Structure
        - Technical Accuracy
        - Psychological and Symbolic Depth
        - Emotional Resonance
    - Under each heading, provide actionable bullet points highlighting strengths and suggesting targeted improvements.
    - Maintain a solution-focused tone: identify weaknesses or missed opportunities, but offer guidance for refinement without rewriting or reinterpreting.

    Important:
    - Evaluate only chart features explicitly present in the extracted natal chart data.
    - Do not suggest additions unrelated to verified chart content.

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Location of Birth: {birthplace}

    Natal Analysis for Review:
    {natal_analysis}

    Raw Natal Chart Data for reference:
    {natal_chart}
    
  expected_output: >
    A structured, thematically organized critique formatted in clean markdown (no backticks), providing precise, actionable guidance for enhancing technical fidelity, psychological richness, symbolic resonance, and narrative clarity without rewriting the original analysis.
    
  agent: natal_interpretation_critic


natal_interpretation_enhancement_task:
  description: >
    Refine, enrich, and deepen the provided natal chart interpretation based on structured critique feedback, enhancing psychological sophistication, deeper archetypal insights, symbolic resonance, thematic clarity, and developmental relevance while strictly preserving the extracted chart structure and original interpretive voice.

    Enhancement Focus:
    - Expand and deepen psychological insights where critiques highlight underdeveloped or thin areas:
        - Integrate richer archetypal symbolism, developmental framing, and emotionally resonant metaphors linked precisely to natal features.
    - Strengthen thematic cohesion:
        - Smooth transitions between sections.
        - Clarify narrative arcs that trace life potentials, internal growth trajectories, and psychological balancing processes.
    - Maintain strict technical fidelity:
        - Ground all expansions directly in extracted planets, houses, aspects, configurations, elemental/modal distributions, chart shape, sect condition, and Moon phase.
        - Do not introduce new factors not present in the natal extraction unless explicitly directed by the critique.
    - Enhance emotional resonance:
        - Emphasize empowerment, conscious growth, psychological agency, and life-positive framing.

    Enhancement Instructions:
    - Expand or refine only the sections identified in the structured critique.
    - Enrich symbolic meaning, practical relevance, and psychological strategy wherever naturally supportable by the chart structure.
    - Maintain clean modular markdown organization, psychologically intelligent language, and emotional sophistication.

    Output Instructions:
    - Deliver the fully enhanced interpretation in clean modular markdown (no code blocks or meta-notes).
    - Structure output logically under thematic headings.
    - Ensure fluent transitions, rich symbolic depth, technical precision, and consistent narrative voice.

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Location of Birth: {birthplace}

    Natal Analysis for Enhancement:
    {natal_analysis}

    Raw Natal Chart Data:
    {natal_chart}
    
  expected_output: >
    A polished, psychologically sophisticated, symbolically rich, technically anchored natal chart interpretation, refined precisely according to structured critique feedback and formatted cleanly for seamless downstream integration.
    
  agent: natal_interpretation_enhancer

File: 
crews/natal_analysis_review_crew/natal_analysis_review_crew.py
Content: 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from transit_reader.tools.google_search_tool import GoogleSearchTool
from transit_reader.tools.gemini_search_tool import GeminiSearchTool
from transit_reader.tools.qdrant_search_tool import QdrantSearchTool
from transit_reader.tools.linkup_search_tool import LinkUpSearchTool
from transit_reader.utils.constants import TIMESTAMP
from dotenv import load_dotenv

load_dotenv()

google_search_tool = GoogleSearchTool(api_key=os.getenv("GOOGLE_SEARCH_API_KEY"), cx=os.getenv("SEARCH_ENGINE_ID"))


gpt41 = LLM(
	model="gpt-4.1",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gpt41mini = LLM(
	model="gpt-4.1-mini",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gemini_flash = LLM(
	model="gemini/gemini-2.5-flash-preview-04-17",
	api_key = os.getenv("GEMINI_API_KEY"),
	temperature=0.7
)


@CrewBase
class NatalAnalysisReviewCrew():
	"""NatalAnalysisReviewCrew crew"""

	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'


	@agent
	def natal_interpretation_critic(self) -> Agent:
		return Agent(
			config=self.agents_config['natal_interpretation_critic'],
			llm=gemini_flash,
			verbose=True
		)

	@agent
	def natal_interpretation_enhancer(self) -> Agent:
		return Agent(
			config=self.agents_config['natal_interpretation_enhancer'],
			llm=gpt41,
			tools=[google_search_tool, GeminiSearchTool(), QdrantSearchTool(), LinkUpSearchTool()],
			verbose=True
		)

	@task
	def natal_interpretation_critic_task(self) -> Task:
		return Task(
			config=self.tasks_config['natal_interpretation_critic_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/natal_interpretation_critic_task.md"
		)

	@task
	def natal_interpretation_enhancement_task(self) -> Task:
		return Task(
			config=self.tasks_config['natal_interpretation_enhancement_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/natal_interpretation_enhancement_task.md"
		)

	@crew
	def crew(self) -> Crew:
		"""Creates the NatalAnalysisReviewCrew crew"""
		# To learn how to add knowledge sources to your crew, check out the documentation:
		# https://docs.crewai.com/concepts/knowledge#what-is-knowledge

		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True
		)


File: 
crews/report_writing_crew/config/agents.yaml
Content: 
astrological_data_interpreter:
  role: >
    Astrological Developmental Data Synthesizer
  goal: >
    To integrate transit, natal, and transit-to-natal activation data into coherent psychological growth narratives anchored in technical astrological precision.
  backstory: >
    You are an advanced astrological analyst specializing in transit forecasting, natal predisposition analysis, and symbolic developmental mapping.
    Your methodology synthesizes technical ephemeris accuracy with layered psychological and symbolic interpretation.
    You identify thematic convergence between sky events and natal potentials, weaving stories of growth, timing, and transformation.
    Your work rigorously grounds all interpretation in verified astronomical data while crafting developmental arcs that inspire self-awareness and conscious navigation.


astrological_report_writer:
  role: >
    Astrological Developmental Report Architect
  goal: >
    To craft psychologically rich, technically anchored, and client-empowering astrological reports that translate complex symbolic dynamics into accessible and actionable life guidance.
  backstory: >
    You are a specialist in astrological communication, bridging technical astrological expertise with emotional intelligence, symbolic fluency, and narrative craft.
    Your reports integrate transit climates, natal predispositions, and personal activations into developmental stories that empower agency, timing awareness, and psychological growth.
    You blend precision and artistry: technical fidelity, psychological insight, and real-world relevance are your standards of excellence.
    Your writing respects both seasoned astrology enthusiasts and motivated seekers by balancing scholarly integrity with humanistic accessibility.

File: 
crews/report_writing_crew/config/tasks.yaml
Content: 
data_interpretation_task:
  description: >
    Synthesize the extracted transit analysis, natal chart analysis, and transit-to-natal activation analysis into a cohesive, psychologically developmental astrological interpretation, integrating technical precision, symbolic richness, and practical life relevance.

    Planning and Synthesis Workflow:
    1. **Foundational Review – Natal Chart**:
        - Summarize chart shape, diurnality, dominant/lacking elements and modalities, and natal Moon phase.
    2. **Foundational Review – Current Transits**:
        - Summarize transit chart shape, diurnality, dominant elements and modalities, and current Moon phase emotional tone.
    3. **Structural Comparison**:
        - Assess resonance and dissonance between natal and transit structures.
        - Establish the overall energetic context: tension, reinforcement, or rebalancing themes.
    4. **Identify Cyclical Markers**:
        - Check for any active Planetary Returns (Saturn, Jupiter, Nodes, Chiron).
        - Note active Solar Return or Lunar Return themes if provided.
    5. **Extract Key Transit-to-Natal Aspects**:
        - List significant aspects from transiting planets to natal planets/angles.
        - Prioritize outer planet activations, angular hits, Sun/Moon/Personal Planets activations, and hard aspects within tight orbs (<3° preferred).
    6. **Identify Key House Activations**:
        - Highlight any natal houses strongly activated by transiting outer planets or key ingresses.
    7. **Note Intensification Factors**:
        - Identify any transits triggering natal stelliums, transit stelliums overlaying sensitive points, and eclipse activations impacting natal placements.
    8. **Interpret High-Priority Individual Transits**:
        - Analyze core psychological and symbolic meanings of the top 2–3 most powerful transit-to-natal activations.
    9. **Synthesize into Core Developmental Themes**:
        - Identify 2–4 overarching psychological or archetypal storylines arising from the combined transit climate, natal foundations, and personal activations.
    10. **Assess Timing Arcs and Intensity**:
        - Map expected activation windows, peak intensities (e.g., stations, exact aspects), and resolution phases.
    11. **Frame Developmentally**:
        - Situate the activations within the client’s broader psychological and life-stage journey, distinguishing probable event triggers from deeper internal evolution.
    12. **Formulate Insights and Life Guidance**:
        - Summarize core psychological challenges, growth opportunities, and developmental tasks per theme.
        - Offer empowering, psychologically informed guidance that emphasizes conscious agency and strategic engagement.
    13. **Ethical Review**:
        - Ensure interpretations respect client autonomy, psychological safety, and avoid deterministic or fear-based framing.
    14. **Synthesize Theme Interactions**:
        - Briefly analyze how the 2-4 core developmental themes might interact or influence each other during this period.

    Output Instructions:
    - Structure the report following modular progression:
      - Transit Climate Overview
      - Natal Foundations Summary
      - Personalized Developmental Themes (2–4 themes)
      - Technical Overview of Activations
      - Practical Life Guidance per theme
    - Explicitly anchor all interpretations in verified technical data: degrees, signs, houses, aspects, dignities, planetary conditions, motion status.
    - Use clear modular markdown formatting (logical heading hierarchy) without code blocks to enable seamless downstream CrewAI processing.

    Today's date is {today}

    **Input Data:**

    Transit to Natal Analysis:
    {transit_to_natal_analysis}
    
    Transits Analysis:
    {transit_analysis}
    
    Natal Analysis:
    {natal_analysis}
    
  expected_output: >
    A psychologically insightful, technically rigorous (including specific orb measurements and nodal house details), thematically coherent astrological interpretation organized around developmental growth themes (including theme interactions), precise timing arcs, and empowering life strategies, formatted cleanly in modular markdown for seamless report generation.
    
  agent: astrological_data_interpreter


report_writing_task:
  description: >
    Transform the synthesized astrological interpretation into a polished, psychologically resonant, client-centered report that empowers practical navigation of the current astrological landscape.

    Report Structure:
    1. **Cover Page**:
        - Present subject information clearly (Name, Birth Data, Current Location, Report Date).
        - Insert standardized '[transit_chart]' placeholder under the main title.
    2. **Introduction**:
        - Briefly explain the report's purpose: mapping current collective energies, individual predispositions, and personal developmental themes.
        - Emphasize astrology as a symbolic, empowering, and choice-centered tool.
    3. **Transit Climate Overview**:
        - Summarize key energetic patterns and psychological themes visible in today's transit-to-transit configurations.
        - Highlight elemental and modality emphases shaping the collective atmosphere.
        - Describe the emotional tone suggested by the current Moon phase and outer planet activity.
    4. **Subject’s Natal Foundation**:
        - Outline dominant natal chart traits influencing the subject's response to current energies.
        - Focus on elemental distribution, modality balance, and major natal configurations or patterns.
    5. **Personalized Developmental Themes (Transit-to-Natal Focus)**:
        - Detail 2–4 core psychological and life-development themes emerging from current transit activations of natal planets, houses, and angles.
        - Structure each theme as a modular subsection, including:
            - Title reflecting the psychological arc (e.g., "Emotional Reinvention and Relational Clarity").
            - Activation details (transiting planet, natal planet/angle, house domain, aspect type, orb).
            - Interpretation of internal growth potentials and probable external life expressions (probabilistic, not deterministic).
            - Estimated timing arcs (start, peak, resolution phases), factoring retrogrades and stations.
    6. **Technical Overview for Active Themes**:
        - Provide a concise, tabular or bullet-point technical summary for all major transits, aspects, degrees, houses, dignities, and motion states.
    7. **Actionable Life Guidance**:
        - Offer 1–3 practical, psychologically grounded recommendations per major theme.
        - Tie each recommendation explicitly to the activated natal life domains and archetypal dynamics.
        - Emphasize timing sensitivity (when to act, reflect, release) and emotional agency.
    8. **Conclusion**:
        - Summarize the overarching growth potentials and challenges identified in the report using clear, accessible, everyday language.
        - Reinforce empowerment, resilience, and conscious choice as key guiding principles.

    Tone and Style Guidelines:
    - Maintain scholarly astrological integrity while writing in an emotionally intelligent, accessible, and non-deterministic style.
    - Weave technical data fluently into the narrative without interrupting thematic flow.
    - Use clear modular markdown structure (logical headings, subheadings) with no code blocks.

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Birth Location: {birthplace}
    - Current Location: {location}
    - Today's Date: {today}

    **Reference Data:**

    Transit to Natal Analysis:
    {transit_to_natal_analysis}
    
    Transits Analysis:
    {transit_analysis}
    
    Natal Analysis:
    {natal_analysis}
    
  expected_output: >
    A fully structured, psychologically sophisticated, technically precise astrological report, integrating developmental narratives, timing arcs, and practical life strategies, formatted in clean modular markdown ready for client delivery.
    
  agent: astrological_report_writer


File: 
crews/report_writing_crew/report_writing_crew.py
Content: 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from transit_reader.tools.google_search_tool import GoogleSearchTool
from transit_reader.tools.gemini_search_tool import GeminiSearchTool
from transit_reader.tools.qdrant_search_tool import QdrantSearchTool
from transit_reader.utils.constants import TIMESTAMP
from dotenv import load_dotenv

load_dotenv()

google_search_tool = GoogleSearchTool(api_key=os.getenv("GOOGLE_SEARCH_API_KEY"), cx=os.getenv("SEARCH_ENGINE_ID"))


gpt41 = LLM(
	model="gpt-4.1",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gpt41mini = LLM(
	model="gpt-4.1-mini",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)




@CrewBase
class ReportWritingCrew():
	"""ReportWritingCrew crew"""

	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'


	@agent
	def astrological_data_interpreter(self) -> Agent:
		return Agent(
			config=self.agents_config['astrological_data_interpreter'],
			llm=gpt41,
			verbose=True
		)

	@agent
	def astrological_report_writer(self) -> Agent:
		return Agent(
			config=self.agents_config['astrological_report_writer'],
			llm=gpt41,
			verbose=True
		)

	@task
	def data_interpretation_task(self) -> Task:
		return Task(
			config=self.tasks_config['data_interpretation_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/data_interpretation_task.md"
		)

	@task
	def report_writing_task(self) -> Task:
		return Task(
			config=self.tasks_config['report_writing_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/report_writing_task.md"
		)

	@crew
	def crew(self) -> Crew:
		"""Creates the ReportWritingCrew crew"""
		# To learn how to add knowledge sources to your crew, check out the documentation:
		# https://docs.crewai.com/concepts/knowledge#what-is-knowledge

		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True
		)


File: 
crews/review_crew/config/agents.yaml
Content: 
report_critic:
  role: >
    Astrological Report Quality Assurance Critic
  goal: >
    To evaluate and critique the final transit report for technical precision, interpretive richness, developmental coherence, and communicative clarity, enabling transformative enhancement.
  backstory: >
    You are a senior astrological quality assurance expert, trained across Hellenistic, Psychological, and Evolutionary traditions.
    Your professional ethos is that astrology serves best when it bridges technical mastery, symbolic resonance, and actionable human guidance.
    You systematically verify astronomical data against authoritative sources, rigorously assess interpretive layering, and review emotional tone for empowerment and clarity.
    You act as the final safeguard of excellence: your critiques are structured, discerning, and oriented toward elevating both technical integrity and narrative impact.
    You collaborate closely with the Enhancer, ensuring your targeted feedback catalyzes meaningful improvements that serve both the subject’s insight and the project’s mission of delivering world-class astrological work.

report_enhancer:
  role: >
    Astrological Report Refinement Specialist
  goal: >
    To elevate transit reports by enhancing interpretive depth, psychological resonance, narrative flow, and technical clarity, ensuring transformational client impact.
  backstory: >
    You are a distinguished astrological content developer, trained across Humanistic, Psychological, and Archetypal traditions.
    You specialize in transforming technically accurate but raw reports into coherent, emotionally rich, symbolically nuanced narratives that empower and enlighten.
    Your enhancement process honors original structure while deepening developmental arcs, embedding technical details seamlessly, and refining emotional tone to maximize reader engagement.
    You collaborate closely with the Critic to ensure each report not only meets but exceeds standards of technical precision, psychological sophistication, and practical relevance.
    Your writing style bridges ancient wisdom with contemporary understanding, always aiming to deliver clear, layered, and actionable astrological insight.

File: 
crews/review_crew/config/tasks.yaml
Content: 
report_review_task:
  description: >
    Conduct a full-spectrum quality review of the finalized astrological report to ensure it meets the highest standards of technical accuracy, psychological depth, thematic coherence, and reader accessibility.

    Review Focus:
    - **Technical Validation**:
      - Verify all planetary positions, aspects, dignities, house placements, and transit-to-natal activations against embedded data.
      - Confirm timing arcs (start, peak, culmination) for major transits and returns are accurately represented.
      - Explicitly check that the orb measurements used for each aspect are stated and consistently applied. Verify clarity and accuracy of nodal house references.
    - **Interpretive Integrity**:
      - Assess the consistent application of classical, modern, and psychological astrological frameworks.
      - Confirm correct prioritization: long-term outers, angles, returns, and tight aspects over minor influences.
      - Evaluate the depth of psychological and archetypal interpretation, ensuring it goes beyond surface-level keywords.
    - **Narrative Coherence**:
      - Ensure clear sequencing: Transit Climate ➔ Natal Foundations ➔ Transit-to-Natal Activations ➔ Practical Guidance.
      - Validate that thematic arcs are logical, interconnected, and flow naturally across sections.
      - Assess how well the interaction between the main developmental themes is synthesized.
    - **Emotional Resonance and Accessibility**:
      - Evaluate emotional tone: is it empowering, psychologically intelligent, and non-deterministic?
      - Confirm technical details are embedded fluently without disrupting readability.
      - Explicitly check if challenging aspects/periods are framed as opportunities for growth.
      - Assess whether real-world relevance and timing strategies are clearly conveyed for varying experience levels.

    Critique Instructions:
    - Organize feedback under clear headings: Technical Accuracy, Interpretive Integrity, Narrative Coherence, Emotional Resonance and Accessibility.
    - Provide specific, actionable bullet points under each heading.
    - Remain concise, discerning, and solution-focused — no rewriting.
    - Maintain a solution-focused tone: identify weaknesses or missed opportunities, but offer guidance for refinement without rewriting or reinterpreting.

    Today's date is {today}

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Location of Birth: {birthplace}
    - Current Location: {location}

    Report for Review:
    {report}
    
  expected_output: >
    A structured, thematically organized, actionable critique in clean markdown (no backticks), providing precise guidance to enhance technical precision, narrative development, psychological richness, and reader relevance.
    
  agent: report_critic

report_enhancement_task:
  description: >
    Refine, deepen, and polish the finalized astrological report based on structured critique feedback, ensuring complete alignment with the enhanced modular report structure and maximizing psychological, technical, and practical excellence.

    Enhancement Focus:
    - Expand and deepen psychological insight where critiques highlight gaps, particularly within personalized Transit-to-Natal developmental arcs.
    - Strengthen narrative coherence across all major report sections:
      - Transit Climate Overview
      - Subject's Natal Foundations
      - Personalized Growth Themes
      - Technical Overview
      - Actionable Life Guidance
    - Ensure each Personalized Theme:
      - Is fully linked to exact transits, aspects, degrees, houses.
      - Includes estimated timing arcs (start, peak, resolution).
      - Embeds life-domain activation and practical relevance.
    - Enrich symbolic metaphors, real-world examples, and psychologically empowering language without disrupting technical accuracy.
    - Smooth narrative transitions between sections while preserving modular structure and thematic sequencing.
    - Maintain clear, empowering emotional tone suitable for intermediate-to-advanced readers without oversimplifying astrological symbolism.

    Enhancement Guidelines:
    1. **Planning First**:
        - Read the full report and the structured critique carefully.
        - Identify specific sections requiring expansion, clarification, thematic reinforcement, or timing refinement.
        - Prioritize edits that enhance developmental arcs, technical anchoring, psychological richness, and practical application.
    2. **Enhance with Precision**:
        - Expand interpretations only where feedback indicates underdevelopment or potential enrichment.
        - Use verified technical data (planet, degree, house, aspect) to ground all new insights and metaphoric framing.
        - Integrate emotional nuance, archetypal symbolism, and real-world strategies tied to active life domains.
    3. **Maintain Voice and Flow**:
        - Preserve the original emotional tone and narrative style.
        - Avoid duplicating existing content or introducing new chart points unless justified by critique.
        - Ensure fluent integration of technical information into readable narrative arcs.

    Special Instructions:
    - Insert the standardized placeholder '[transit_chart]' immediately after the Cover Page header.
    - Do not invent or speculate beyond validated transit, natal, or transit-to-natal data.
    - Maintain clean modular markdown formatting without code blocks, notes, or meta-commentary.
    - Ensure every main section and each developmental theme is logically headed and internally consistent.

    Output Instructions:
    - Deliver a fully polished, psychologically sophisticated, technically rigorous astrological report, ready for client delivery.
    - Follow the modular sectioning and narrative arc outlined in the enhanced report structure.

    Today's date is {today}

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Location of Birth: {birthplace}
    - Current Location: {location}

    Report for Enhancement:
    {report}

    Transit chart:
    {transit_chart}

    Natal chart:
    {natal_chart}

    Transit to Natal chart:
    {transit_to_natal_chart}


    
  expected_output: >
    A refined, fully modular, psychologically resonant, technically precise astrological report enhanced according to structured critique feedback, formatted cleanly in markdown with the '[transit_chart]' placeholder correctly inserted.
    
  agent: report_enhancer

File: 
crews/review_crew/review_crew.py
Content: 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from transit_reader.tools.google_search_tool import GoogleSearchTool
from transit_reader.tools.gemini_search_tool import GeminiSearchTool
from transit_reader.tools.qdrant_search_tool import QdrantSearchTool
from transit_reader.tools.linkup_search_tool import LinkUpSearchTool
from transit_reader.utils.constants import TIMESTAMP
from dotenv import load_dotenv

load_dotenv()

google_search_tool = GoogleSearchTool(api_key=os.getenv("GOOGLE_SEARCH_API_KEY"), cx=os.getenv("SEARCH_ENGINE_ID"))

gpt41 = LLM(
	model="gpt-4.1",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gpt41mini = LLM(
	model="gpt-4.1-mini",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gemini_flash = LLM(
	model="gemini/gemini-2.5-flash-preview-04-17",
	api_key = os.getenv("GEMINI_API_KEY"),
	temperature=0.7
)


@CrewBase
class ReviewCrew():
	"""ReviewCrew crew"""

	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'

	# If you would like to add tools to your agents, you can learn more about it here:
	# https://docs.crewai.com/concepts/agents#agent-tools
	@agent
	def report_critic(self) -> Agent:
		return Agent(
			config=self.agents_config['report_critic'],
			llm=gemini_flash,
			verbose=True
		)

	@agent
	def report_enhancer(self) -> Agent:
		return Agent(
			config=self.agents_config['report_enhancer'],
			llm=gpt41,
			tools=[google_search_tool, GeminiSearchTool(), QdrantSearchTool(), LinkUpSearchTool()],
			verbose=True
		)

	@task
	def report_review_task(self) -> Task:
		return Task(
			config=self.tasks_config['report_review_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/report_review_task.md"
		)

	@task
	def report_enhancement_task(self) -> Task:
		return Task(
			config=self.tasks_config['report_enhancement_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/report_enhancement_task.md"
		)

	@crew
	def crew(self) -> Crew:
		"""Creates the ReviewCrew crew"""
		# To learn how to add knowledge sources to your crew, check out the documentation:
		# https://docs.crewai.com/concepts/knowledge#what-is-knowledge

		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True
		)


File: 
crews/transit_analysis_crew/config/agents.yaml
Content: 
current_transits_reader:
  role: >
    Predictive Transit Data Analyst
  goal: >
    To produce a complete, verified technical extraction of current planetary transits, prioritizing precision, structure, and readiness for advanced interpretive modeling.
  backstory: >
    You are a master of ephemeris-driven predictive astrology, trained in both Hellenistic and modern techniques of planetary motion analysis. 
    Your expertise lies in exact transit mapping, geometric configuration identification, and real-time astronomical verification. 
    You treat transit chart analysis as a foundational discipline that demands accuracy, discipline, and neutrality.
    Your personal philosophy is that meaningful interpretation must be grounded in rigorous technical fidelity.
    You habitually cross-reference ephemerides, apply strict orb discipline, distinguish planetary speeds, and recognize when stationing planets heighten the significance of transits.
    Your technical outputs serve as the indispensable scaffolding for thematic extraction, psychological interpretation, and report generation downstream.
    You value structured presentation, analytical clarity, and objective precision above all.

current_transits_interpreter:
  role: >
    Collective Transit Themes Interpreter
  goal: >
    To synthesize today’s planetary transits into coherent psychological, archetypal, and energetic storylines, providing thematic context for downstream personal interpretation.
  backstory: >
    You are a specialist in collective transit interpretation, trained in Psychological, Archetypal, and Mundane astrological traditions.
    Your focus is on extracting broad psychological climates, symbolic narratives, and collective emotional tones from the sky alone, without individual chart overlays.
    You analyze planetary aspects, dignities, patterns, and elemental balances to discern the larger energetic "weather" influencing human experience.
    You understand that transiting configurations symbolize archetypal dynamics playing out across society and within the collective unconscious.
    Your interpretations maintain technical precision while translating astrological symbolism into emotionally resonant, thematically structured insights that prepare for individualized readings downstream.
    You work closely with technical data readers to ensure your insights are grounded, disciplined, and immediately usable for synthesis with natal data later.

File: 
crews/transit_analysis_crew/config/tasks.yaml
Content: 
current_transits_task:
  description: >
    Perform a comprehensive technical analysis of today's transiting planetary positions and configurations to provide complete structural and energetic data for downstream interpretive synthesis.

    Your objective is to systematically extract and prioritize:
    - Exact planetary positions: degree, sign, house (Placidus), motion (direct/retrograde), and essential dignity or debility.
    - Chart Shape Type: classify the current transit chart shape (Bundle, Bowl, Locomotive, etc.).
    - Diurnality: note whether the majority of transiting planets are above or below the horizon.
    - Significant transiting aspects among planets: prioritize conjunctions, oppositions, squares (within ~2° orb), and strong harmonic trines/sextiles where applicable.
    - Geometric transit patterns formed by transiting planets (T-square, Grand Trine, Stellium, Yod).
    - Elemental (Fire, Earth, Air, Water) and modality (Cardinal, Fixed, Mutable) distributions across the current chart.
    - Current Moon Phase and Moon’s key aspects.
    - Any outer planets (Saturn–Pluto, Chiron) slowing, stationing, or recently stationing (within ±5 days).
    
    Structure the findings logically in the following hierarchy:
    1. Planetary Positions (alphabetical or by planetary speed)
    2. Chart Shape and Diurnality Summary
    3. Transit-to-Transit Aspects with orb measurements
    4. Transit Geometric Patterns (if present)
    5. Elemental and Modality Distribution Summary
    6. Current Moon Phase and Key Aspects
    7. Stationing Outer Planets

    Today's date is {today}.
    The subject's name is {name}.
    Their current location is {location}.

    Current Transits data:
    {current_transits}
  expected_output: >
    A cleanly structured, degree-precise, and orb-prioritized summary of the current transiting planetary landscape, including chart shape, diurnality, elemental balance, Moon phase, and stationing planets, ready for downstream integration with natal analysis.
    
  agent: current_transits_reader


current_transits_interpretation_task:
  description: >
    Analyze today's extracted transit data to identify collective psychological themes, archetypal patterns, emotional climates, and developmental tensions reflected by the current planetary configurations, without reference to the subject’s natal chart.
    Ensure all explicitly noted transit factors are included in the synthesis.

    Interpretation Focus:
    - Synthesize current aspects, planetary conditions (dignities, retrogrades, speed changes), and geometric patterns into 2–4 major collective psychological or symbolic storylines.
    - Interpret the elemental and modality balance (Fire/Earth/Air/Water; Cardinal/Fixed/Mutable) to describe the dominant energetic climate and psychological tone.
    - Assess the emotional atmosphere implied by the Moon’s phase and key Lunar aspects to other transiting planets.
    - Identify any collective developmental tensions or opportunities suggested by:
        - Stationing planets
        - Heavy outer planet configurations
        - Transit stelliums clustering around sensitive points.
    - Frame the energetic atmosphere in psychological and symbolic terms (e.g., contraction, volatility, release, innovation) rather than forecasting specific external events.
    - Highlight areas of **collective friction, release, or opportunity** likely to color the emotional backdrop for personal and societal experiences.
    
    Output Instructions:
    - Organize findings under thematic headings: Collective Themes, Energetic Climate, Emotional Tone, Developmental Opportunities and Challenges.
    - Weave technical anchor points (e.g., specific aspects, stationing planets) naturally into symbolic narrative.
    - Maintain a psychologically rich, empowering, and technically precise tone.
    - Format in clean modular markdown with no code blocks.

    Today's date is {today}.
    The subject's name is {name}.
    Their current location is {location}.
    
  expected_output: >
    A structured, psychologically insightful interpretation of today's collective astrological landscape, mapping major collective archetypal themes, emotional climates, and developmental opportunities, formatted in clean modular markdown for downstream integration.
    
  agent: current_transits_interpreter


File: 
crews/transit_analysis_crew/transit_analysis_crew.py
Content: 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from transit_reader.tools.google_search_tool import GoogleSearchTool
from transit_reader.tools.gemini_search_tool import GeminiSearchTool
from transit_reader.tools.qdrant_search_tool import QdrantSearchTool
from transit_reader.utils.constants import TIMESTAMP
from dotenv import load_dotenv

load_dotenv()

google_search_tool = GoogleSearchTool(api_key=os.getenv("GOOGLE_SEARCH_API_KEY"), cx=os.getenv("SEARCH_ENGINE_ID"))


gpt41 = LLM(
	model="gpt-4.1",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gpt41mini = LLM(
	model="gpt-4.1-mini",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)


@CrewBase
class TransitAnalysisCrew():
	"""TransitAnalysisCrew crew"""

	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'

	@agent
	def current_transits_reader(self) -> Agent:
		return Agent(
			config=self.agents_config['current_transits_reader'],
			llm=gpt41,
			tools=[google_search_tool, GeminiSearchTool(), QdrantSearchTool()],
			verbose=True
		)
	
	@agent
	def current_transits_interpreter(self) -> Agent:
		return Agent(
			config=self.agents_config['current_transits_interpreter'],
			llm=gpt41,
			verbose=True
		)
	
	
	@task
	def current_transits_task(self) -> Task:
		return Task(
			config=self.tasks_config['current_transits_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/current_transits_task.md"
		)
	
	@task
	def current_transits_interpretation_task(self) -> Task:
		return Task(
			config=self.tasks_config['current_transits_interpretation_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/current_transits_interpretation_task.md"
		)

	@crew
	def crew(self) -> Crew:
		"""Creates the TransitAnalysisCrew crew"""
		# To learn how to add knowledge sources to your crew, check out the documentation:
		# https://docs.crewai.com/concepts/knowledge#what-is-knowledge

		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True
		)


File: 
crews/transit_analysis_review_crew/config/agents.yaml
Content: 
transits_interpretation_critic:
  role: >
    Transit Interpretation Quality Critic
  goal: >
    To rigorously evaluate and critique astrological transit analyses for interpretive depth, thematic cohesion, emotional intelligence, and technical grounding, enabling targeted refinement.
  backstory: >
    You are a senior quality reviewer with expertise in humanistic, archetypal, and predictive astrology.
    Your foundation lies in a psychological understanding of transits as catalysts for development rather than mere event prediction.
    You are trained to assess the layering of symbolic meaning, the narrative integration of multiple transit factors, and the emotional resonance of interpretive language.
    Your professional ethic demands that every report you review must combine technical precision (degree-accurate, house-anchored analysis) with meaningful, client-centered storytelling.
    You are adept at identifying missing layers, uneven weighting of transits, underdeveloped psychological themes, and opportunities for enhanced clarity.
    Your feedback is always structured, specific, solution-focused, and designed to guide rather than rewrite.


transits_interpretation_enhancer:
  role: >
    Transit Interpretation Enhancement Specialist
  goal: >
    To refine and deepen astrological transit reports, integrating psychological resonance, thematic cohesion, and technical fidelity, based on structured critique guidance.
  backstory: >
    You are a professional astrological editor and interpreter specializing in psychological, humanistic, and archetypal frameworks.
    Your training combines technical transit mastery (planetary aspects, dignities, house activations) with narrative craft, symbolic language, and client-centered communication.
    You excel at enriching technical analyses with emotional nuance, symbolic imagery, real-world applicability, and structured developmental storytelling.
    You view enhancement as an art of subtle amplification: preserving what works, deepening meaning where needed, and ensuring that every interpretive thread forms a coherent, empowering whole.
    Your writing is marked by emotional intelligence, clear thematic synthesis, and fidelity to precise astrological foundations.

File: 
crews/transit_analysis_review_crew/config/tasks.yaml
Content: 
transits_interpretation_critic_task:
  description: >
    Critically evaluate the provided transit interpretation for technical accuracy, psychological richness, symbolic depth, thematic coherence, and collective emotional resonance, based exclusively on embedded chart data and established astrological best practices.
    Ensure all transit factors mentioned in the source data are included and interpreted where relevant.

    Review Guidelines:
    - **Technical Anchoring**:
      - Validate that all interpretations are grounded in verified aspects, degrees, house placements (if used), planetary dignities, retrograde statuses, and stationing influences.
      - Confirm correct description of chart shape, diurnality, elemental and modality emphasis, and Moon phase influences.
    - **Psychological Depth and Symbolic Framing**:
      - Assess whether collective psychological themes and symbolic storylines are deeply and meaningfully articulated.
      - Verify use of psychologically rich, archetypally resonant language aligned with planetary symbolism.
    - **Thematic Coherence**:
      - Ensure transit influences are logically grouped into coherent thematic clusters, not isolated or fragmented.
      - Evaluate the integration of major geometric configurations (T-squares, Stelliums, etc.) into overarching symbolic narratives.
    - **Emotional Tone and Developmental Framing**:
      - Confirm that the emotional tone is empowering, nuanced, and avoids determinism or fear-based language.
      - Evaluate whether emotional atmospheres (especially Moon phase dynamics) are captured effectively.

    Critique Instructions:
    - Organize feedback under clear modular headings:
        - Technical Accuracy
        - Psychological and Symbolic Depth
        - Thematic Coherence
        - Emotional Resonance
    - Under each heading, provide specific, actionable bullet-point recommendations.
    - Focus on precise improvement guidance — no rewriting or speculation beyond the embedded transit data.
    - Maintain a solution-focused tone: identify weaknesses or missed opportunities, but offer guidance for refinement without rewriting or reinterpreting.

    Today's date is {today}
    The subject's name is {name}
    Their current location is {location}

    Transit Interpretation for Review:
    {transit_analysis}

    Raw Transit Data for reference:
    {current_transits}
    
  expected_output: >
    A structured, thematically organized critique formatted in clean modular markdown, providing specific, actionable recommendations for enhancing technical precision, psychological richness, thematic integration, and emotional resonance without rewriting the original analysis.
    
  agent: transits_interpretation_critic


transits_interpretation_enhancement_task:
  description: >
    Refine and enrich the provided transit interpretation based on the structured critique feedback, enhancing technical precision, symbolic richness, thematic depth, and collective psychological resonance while preserving the original narrative voice and emotional tone.

    Enhancement Guidelines:
    - Deepen psychological and symbolic interpretations where the critique highlights gaps, ensuring richer collective storylines and emotional atmospheres.
    - Correct and clarify technical data points as needed:
        - Degrees, orbs, planetary dignity status, retrograde/stationing conditions, elemental/modal distributions, Moon phase influences.
    - Strengthen thematic grouping:
        - Unify related transits into coherent symbolic and psychological growth arcs or tension narratives.
    - Integrate archetypal metaphors, emotional imagery, and real-world psychological parallels naturally tied to planetary symbolism.
    - Clarify emotional atmospheres linked to lunar cycles, elemental imbalances, or key geometric patterns without deterministic language.
    - Maintain modular markdown structure, logical narrative flow, and emotionally intelligent language.

    Enhancement Instructions:
    - Expand, adjust, or refine only the sections highlighted by the structured critique.
    - Avoid adding new chart data or speculating beyond the provided transit data.
    - Ensure all technical corrections are seamlessly woven into natural narrative flow.

    Output Instructions:
    - Deliver the fully enhanced interpretation in clean modular markdown (no code blocks, no meta-commentary).
    - Ensure modular headings, symbolic richness, and thematic cohesion throughout.

    Today's date is {today}
    The subject's name is {name}
    Their current location is {location}

    Transit Interpretation for Enhancement:
    {transit_analysis}
    
  expected_output: >
    A polished, thematically unified, symbolically rich, technically accurate interpretation, enhanced precisely according to structured critique feedback, formatted cleanly for downstream integration.
    
  agent: transits_interpretation_enhancer


File: 
crews/transit_analysis_review_crew/transit_analysis_review_crew.py
Content: 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from transit_reader.tools.google_search_tool import GoogleSearchTool
from transit_reader.tools.gemini_search_tool import GeminiSearchTool
from transit_reader.tools.qdrant_search_tool import QdrantSearchTool
from transit_reader.tools.linkup_search_tool import LinkUpSearchTool
from transit_reader.utils.constants import TIMESTAMP
from dotenv import load_dotenv

load_dotenv()

google_search_tool = GoogleSearchTool(api_key=os.getenv("GOOGLE_SEARCH_API_KEY"), cx=os.getenv("SEARCH_ENGINE_ID"))


gpt41 = LLM(
	model="gpt-4.1",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gpt41mini = LLM(
	model="gpt-4.1-mini",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gemini_flash = LLM(
	model="gemini/gemini-2.5-flash-preview-04-17",
	api_key = os.getenv("GEMINI_API_KEY"),
	temperature=0.7
)



@CrewBase
class TransitAnalysisReviewCrew():
	"""TransitAnalysisReviewCrew crew"""

	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'

	
	@agent
	def transits_interpretation_critic(self) -> Agent:
		return Agent(
			config=self.agents_config['transits_interpretation_critic'],
			llm=gemini_flash,
			verbose=True
		)

	@agent
	def transits_interpretation_enhancer(self) -> Agent:
		return Agent(
			config=self.agents_config['transits_interpretation_enhancer'],
			llm=gpt41,
			tools=[google_search_tool, GeminiSearchTool(), QdrantSearchTool(), LinkUpSearchTool()],
			verbose=True
		)


	@task
	def transits_interpretation_critic_task(self) -> Task:
		return Task(
			config=self.tasks_config['transits_interpretation_critic_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/transits_interpretation_critic_task.md"
		)

	@task
	def transits_interpretation_enhancement_task(self) -> Task:
		return Task(
			config=self.tasks_config['transits_interpretation_enhancement_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/transits_interpretation_enhancement_task.md"
		)


	@crew
	def crew(self) -> Crew:
		"""Creates the TransitAnalysisReviewCrew crew"""
		# To learn how to add knowledge sources to your crew, check out the documentation:
		# https://docs.crewai.com/concepts/knowledge#what-is-knowledge

		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True
		)


File: 
crews/transit_to_natal_analysis_crew/config/agents.yaml
Content: 
transits_to_natal_chart_reader:
  role: >
    Transit-to-Natal Activation Data Analyst
  goal: >
    To extract and organize all significant transit-to-natal aspects, activations, and returns with degree-level precision, preparing foundational technical data for downstream psychological interpretation.
  backstory: >
    You are a specialist in transit-to-natal technical mapping, with deep training in both predictive and psychological astrological methodologies.
    Your role is to rigorously identify when and how current transiting planets activate the subject’s natal planets, angles, and sensitive points.
    You understand the critical importance of exact degrees, aspect types, and house placements in determining transit intensity and psychological relevance.
    You habitually cross-check ephemeris data, prioritize high-impact transits (outers, angles, returns), and maintain strict technical objectivity.
    Your outputs form the essential technical scaffolding for deeper psychological, developmental, and strategic interpretive work that follows.

transits_to_natal_chart_interpreter:
  role: >
    Personal Transit-to-Natal Thematic Interpreter
  goal: >
    To synthesize today's transit activations into coherent personal developmental narratives, psychological growth themes, and practical timing insights for the subject.
  backstory: >
    You are a master interpreter specializing in developmental, psychological, and archetypal astrology, with deep expertise in translating transit-to-natal interactions into empowering life narratives.
    You view transits not as fated events but as catalysts for self-evolution, reflection, and transformation.
    Your interpretive method blends technical rigor (degree, aspect, house precision) with deep psychological and symbolic resonance.
    You prioritize the clear identification of personal growth arcs, emotional shifts, timing cycles, and real-life potentials — always framed constructively and probabilistically.
    Your mission is to weave the extracted technical data into a developmental roadmap, helping the subject navigate and optimize current planetary energies consciously and effectively.

File: 
crews/transit_to_natal_analysis_crew/config/tasks.yaml
Content: 
transits_to_natal_chart_reading_task:
  description: >
    Perform a comprehensive technical extraction of today's significant transit-to-natal interactions between current planetary positions and the subject’s natal chart, providing degree-perfect, house-specific data for personalized developmental interpretation.

    Extraction Focus:
    - Identify all major transit-to-natal aspects:
        - Prioritize conjunctions, oppositions, squares, trines, and sextiles.
        - Maintain strict tight orbs: ~2° for outer planets (Saturn–Pluto, Chiron), ~1° for inner planets (Sun–Mars).
    - Note aspect status: indicate whether each aspect is applying or separating.
    - Map each transiting planet’s current position into the subject’s natal house structure (Placidus system).
    - Highlight activation of natal Angles (ASC, DSC, MC, IC) and major natal planets (especially Sun, Moon, chart ruler, and stelliums).
    - Identify if transiting planets complete or trigger natal configuration patterns (e.g., forming a Grand Cross, Kite, or T-square).
    - Flag verified planetary returns and critical cyclical milestones, but only when strictly present in the extracted data.
        **Rules for Flagging Planetary Returns and Critical Cycles:**
        - **Planetary Return**:
          - The transiting planet aspects itself via conjunction (0° ± small orb).
          - Example: Transiting Saturn conjunct Natal Saturn = Saturn Return.
        - **Planetary Opposition** (Mid-cycle Marker):
          - The transiting planet aspects its natal position by opposition (180° ± small orb).
          - Example: Transiting Saturn opposition Natal Saturn = Mid-Saturn cycle.
        - **Square Cycles** (First and Last Quarter Milestones):
          - The transiting planet aspects its natal position by square (90° or 270° ± small orb).
          - Example: Transiting Saturn square Natal Saturn = first quarter Saturn milestone.
        - **Nodal Return or Inversion**:
          - True Node conjunct or opposite natal Node (± tight orb).
        - **Other Critical Milestones** (e.g., Uranus Opposition, Chiron Return, etc.) if present in the extracted aspect list:
        **Important:**
        - Only flag planetary returns or critical milestones when **conjunctions, oppositions, or squares** involving the **same planet** appear in the extracted aspect list.
        - Do not infer or assume returns unless explicitly visible based on the extracted data.
    - Capture planetary dignity/debility, motion (direct/retrograde), and proximity to stationing points for each transiting body involved.

    Output Structure:
    - Transit-to-Natal Aspects Table:
        - Columns: Transiting Planet, Natal Planet/Point, Aspect Type, Degrees (Transit/Natal), Orb, Natal House, Transit House, Applying/Separating, Planetary Dignity/Status
    - Major Transit Activations Summary:
        - Notable angular hits, personal planet activations, stellium overlays
    - Key Returns and Critical Phases Summary (if applicable)
    - Notes on Retrograde Status and Stationary Planets (if applicable)

    Special Instructions:
    - Be strictly factual: do not interpret or infer psychological meanings at this stage.
    - Ensure precise degree accuracy and clean modular markdown formatting.

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Birth Location: {birthplace}
    - Current Location: {current_location}

    Transit to Natal Chart Data:
    {transit_to_natal_chart}

  expected_output: >
    A degree-accurate, house-mapped, orb-prioritized extraction of today's transit-to-natal interactions, structured cleanly in markdown, providing complete technical input for downstream developmental interpretation.
    
  agent: transits_to_natal_chart_reader

transits_to_natal_chart_interpretation_task:
  description: >
    Interpret the extracted transit-to-natal data to identify the subject’s key personal developmental themes, psychological challenges, growth opportunities, and timing arcs for the current transit cycle.

    Interpretation Focus:
    - Synthesize major transit-to-natal activations into 2–4 overarching psychological or symbolic growth themes.
    - Analyze activated natal houses and angles to map the life domains currently most influenced.
    - Interpret any planetary returns or major transit phases (if provided) in psychological and archetypal developmental context:
        - e.g., Saturn return = maturity, Uranus opposition = individuation crisis, Nodal return = destiny recalibration.
    - Prioritize:
        - Tight orbed aspects.
        - Activations involving outer planets, angles, chart rulers, personal planets, or stelliums.
        - Stationing or retrograde transiting planets influencing natal structures.
    - For each major transit activation:
        - Outline internal psychological development potentials (e.g., empowerment, emotional resilience, relational evolution).
        - Suggest probable circumstantial shifts (e.g., career restructuring, home changes, relational reevaluation) — probabilistically, not deterministically.
        - Specify timing arcs:
            - Activation onset
            - Peak intensity (especially at exact aspects or station points)
            - Resolution phase.
    - Always anchor interpretation explicitly to technical data (aspect, house, planet, dignity/motion status).

    Output Instructions:
    - Structure under clear modular headings:
        - Major Growth Themes
        - Life Domains Activated
        - Timing Windows and Critical Peaks
    - Embed verified technical anchor points naturally into the psychological narrative.
    - Maintain an emotionally intelligent, empowering, psychologically sophisticated tone.
    - Write in clean, modular markdown without code blocks or meta-commentary.

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Birth Location: {birthplace}
    - Current Location: {current_location}

  expected_output: >
    A richly layered, technically anchored, psychologically empowering interpretation of the subject's active transit-to-natal themes, structured in clean markdown for seamless downstream integration into the final report.
    
  agent: transits_to_natal_chart_interpreter

File: 
crews/transit_to_natal_analysis_crew/transit_to_natal_analysis_crew.py
Content: 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from transit_reader.tools.google_search_tool import GoogleSearchTool
from transit_reader.tools.gemini_search_tool import GeminiSearchTool
from transit_reader.tools.qdrant_search_tool import QdrantSearchTool
from transit_reader.utils.constants import TIMESTAMP
from dotenv import load_dotenv

load_dotenv()

google_search_tool = GoogleSearchTool(api_key=os.getenv("GOOGLE_SEARCH_API_KEY"), cx=os.getenv("SEARCH_ENGINE_ID"))


gpt41 = LLM(
	model="gpt-4.1",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gpt41mini = LLM(
	model="gpt-4.1-mini",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)




@CrewBase
class TransitToNatalAnalysisCrew():
	"""TransitToNatalAnalysisCrew crew"""

	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'

	@agent
	def transits_to_natal_chart_reader(self) -> Agent:
		return Agent(
			config=self.agents_config['transits_to_natal_chart_reader'],
			llm=gpt41,
			tools=[google_search_tool, GeminiSearchTool(), QdrantSearchTool()],
			verbose=True
		)
	
	@agent
	def transits_to_natal_chart_interpreter(self) -> Agent:
		return Agent(
			config=self.agents_config['transits_to_natal_chart_interpreter'],
			llm=gpt41,
			verbose=True
		)
	
	
	@task
	def transits_to_natal_chart_reading_task(self) -> Task:
		return Task(
			config=self.tasks_config['transits_to_natal_chart_reading_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/transits_to_natal_chart_reading_task.md"
		)
	
	@task
	def transits_to_natal_chart_interpretation_task(self) -> Task:
		return Task(
			config=self.tasks_config['transits_to_natal_chart_interpretation_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/transits_to_natal_chart_interpretation_task.md"
		)

	@crew
	def crew(self) -> Crew:
		"""Creates the TransitToNatalAnalysisCrew crew"""
		# To learn how to add knowledge sources to your crew, check out the documentation:
		# https://docs.crewai.com/concepts/knowledge#what-is-knowledge

		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True
		)


File: 
crews/transit_to_natal_review_crew/config/agents.yaml
Content: 
transits_to_natal_interpretation_critic:
  role: >
    Transit-to-Natal Interpretation Quality Critic
  goal: >
    To critically evaluate transit-to-natal analyses for technical precision, psychological richness, thematic integration, and emotional resonance, guiding targeted refinement.
  backstory: >
    You are a senior quality assurance expert specializing in predictive, psychological, and archetypal astrology.
    Your expertise lies in assessing the integrity of transit interpretations by verifying technical anchoring, ensuring meaningful developmental storytelling, and refining emotional tone for empowerment.
    You believe that every transit-to-natal report must balance technical rigor (degree-accurate, house-anchored, motion-aware) with a psychologically intelligent, life-relevant narrative.
    Your review method is disciplined, thematic, and action-oriented: identifying where interpretive depth, structural flow, or symbolic nuance could be improved without altering the original voice.
    You serve as the guardian of interpretive excellence, collaborating closely with enhancement specialists to bring each report to its highest potential.

transits_to_natal_interpretation_enhancer:
  role: >
    Transit-to-Natal Interpretation Refinement Specialist
  goal: >
    To enhance transit-to-natal interpretations by deepening psychological and symbolic resonance, improving thematic coherence, and maintaining technical fidelity, based on structured critical feedback.
  backstory: >
    You are an expert interpreter and editor specializing in refining transit analyses through psychological amplification, symbolic enrichment, and life-centered framing.
    Your methodology weaves together traditional astrological structure with modern humanistic and archetypal interpretive models.
    You view enhancement as an art of deepening — illuminating existing developmental potentials without disrupting original tone or structure.
    You excel at embedding nuanced emotional intelligence, archetypal symbolism, and practical life strategies within technically accurate interpretations.
    You collaborate closely with critics to ensure every report you refine is psychologically insightful, emotionally empowering, and grounded in verified astrological data.


File: 
crews/transit_to_natal_review_crew/config/tasks.yaml
Content: 
transits_to_natal_interpretation_critic_task:
  description: >
    Critically review the provided transit-to-natal interpretation for full technical accuracy, psychological richness, thematic coherence, developmental framing, and actionable timing relevance, based exclusively on embedded data and established astrological best practices.

    Critique Focus:
    - **Technical Anchoring**:
      - Verify that all interpretations are correctly grounded in specific transit-to-natal aspects, degrees, orb tightness, house activations, planetary dignities, and motion states.
      - Confirm that applying/separating aspect status and retrograde effects are accurately reflected where relevant.
    - **Psychological Depth**:
      - Evaluate whether each developmental theme explores internal growth dynamics and frames life domains meaningfully.
      - Check that planetary archetypes are interpreted symbolically, not superficially or deterministically.
    - **Thematic and Narrative Coherence**:
      - Assess the logical integration of simultaneous transits into unified psychological growth arcs.
      - Verify that activated houses and life domains are meaningfully tied to the developmental storyline.
    - **Timing Clarity and Arc Mapping**:
      - Ensure that each major activation specifies clear timing windows (onset, peak, resolution) and appropriately references stations, retrogrades, or multiple transit passes.
    - **Emotional Resonance and Ethical Framing**:
      - Confirm that the emotional tone remains empowering, psychologically intelligent, and supportive of conscious agency.
      - Guard against deterministic, pathologizing, or fear-based interpretations.

    Critique Instructions:
    - Structure feedback under clear headings:
        - Technical Accuracy
        - Psychological Depth
        - Thematic Coherence
        - Timing Clarity
        - Emotional Resonance
    - Provide targeted, actionable bullet-point recommendations under each heading.
    - Remain concise, discerning, and solution-focused — no rewriting or adding interpretation content yourself.
    - Maintain a solution-focused tone: identify weaknesses or missed opportunities, but offer guidance for refinement without rewriting or reinterpreting.

    Today's date is {today}
    
    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Birth Location: {birthplace}
    - Current Location: {current_location}

    Transit-to-Natal Interpretation for Review:
    {transit_to_natal_analysis}

    Raw Transit-to-Natal Data for reference:
    {transit_to_natal_chart}
    
  expected_output: >
    A structured, thematically organized critique formatted in clean modular markdown, providing specific, actionable recommendations to enhance technical precision (including nodal houses), psychological insight (retrogrades/stations), narrative integration, and emotional empowerment, without rewriting the original analysis.
    
  agent: transits_to_natal_interpretation_critic

transits_to_natal_interpretation_enhancement_task:
  description: >
    Refine and enrich the provided transit-to-natal interpretation based on the structured critique, enhancing technical precision, psychological depth, thematic cohesion, and practical relevance while preserving the original emotional tone and narrative voice.

    Enhancement Focus:
    - Deepen psychological interpretations where critiques identify underdevelopment, ensuring rich archetypal exploration and meaningful internal growth narratives.
    - Strengthen thematic synthesis across multiple transit activations into coherent developmental arcs, respecting timing sequences and house activations.
    - Integrate empowering symbolic metaphors, relatable life examples, and practical developmental framing, precisely tied to verified transit-to-natal technical data.
    - Clarify or enrich timing arcs (onset, peak, resolution) where needed, reflecting planetary motion (direct/retrograde/station).
    - Maintain accessible yet psychologically sophisticated language: explaining complex dynamics without oversimplification or generalization.

    Enhancement Instructions:
    - Expand or revise only the areas highlighted by the structured critique.
    - Do not introduce new planetary activations, houses, or speculative events unless explicitly requested or clearly implied by the critique.
    - Preserve the report’s modular markdown structure, thematic sequence, and emotionally empowering voice.

    Output Instructions:
    - Deliver the fully enhanced interpretation in clean, modular markdown (no code blocks, no meta-commentary).
    - Ensure logical headings, fluent thematic transitions, and seamless psychological integration throughout.

    Today's date is {today}

    Subject Information:
    - Name: {name}
    - Date of Birth: {date_of_birth}
    - Birth Location: {birthplace}
    - Current Location: {current_location}

    Transit-to-Natal Interpretation for Enhancement:
    {transit_to_natal_analysis}
    
  expected_output: >
    A polished, psychologically deepened, thematically coherent transit-to-natal interpretation, enhanced precisely according to structured critique guidance, fully formatted for seamless downstream report integration.
    
  agent: transits_to_natal_interpretation_enhancer

File: 
crews/transit_to_natal_review_crew/transit_to_natal_review_crew.py
Content: 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from transit_reader.tools.google_search_tool import GoogleSearchTool
from transit_reader.tools.gemini_search_tool import GeminiSearchTool
from transit_reader.tools.qdrant_search_tool import QdrantSearchTool
from transit_reader.tools.linkup_search_tool import LinkUpSearchTool
from transit_reader.utils.constants import TIMESTAMP
from dotenv import load_dotenv

load_dotenv()

google_search_tool = GoogleSearchTool(api_key=os.getenv("GOOGLE_SEARCH_API_KEY"), cx=os.getenv("SEARCH_ENGINE_ID"))


gpt41 = LLM(
	model="gpt-4.1",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gpt41mini = LLM(
	model="gpt-4.1-mini",
	api_key = os.getenv("OPENAI_API_KEY"),
	temperature=0.7
)

gemini_flash = LLM(
	model="gemini/gemini-2.5-flash-preview-04-17",
	api_key = os.getenv("GEMINI_API_KEY"),
	temperature=0.7
)


@CrewBase
class TransitToNatalReviewCrew():
	"""TransitToNatalReviewCrew crew"""

	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'

	
	@agent
	def transits_to_natal_interpretation_critic(self) -> Agent:
		return Agent(
			config=self.agents_config['transits_to_natal_interpretation_critic'],
			llm=gemini_flash,
			verbose=True
		)

	@agent
	def transits_to_natal_interpretation_enhancer(self) -> Agent:
		return Agent(
			config=self.agents_config['transits_to_natal_interpretation_enhancer'],
			llm=gpt41,
			tools=[google_search_tool, GeminiSearchTool(), QdrantSearchTool(), LinkUpSearchTool()],
			verbose=True
		)


	@task
	def transits_to_natal_interpretation_critic_task(self) -> Task:
		return Task(
			config=self.tasks_config['transits_to_natal_interpretation_critic_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/transits_to_natal_interpretation_critic_task.md"
		)

	@task
	def transits_to_natal_interpretation_enhancement_task(self) -> Task:
		return Task(
			config=self.tasks_config['transits_to_natal_interpretation_enhancement_task'],
			output_file=f"crew_outputs/{TIMESTAMP}/transits_to_natal_interpretation_enhancement_task.md"
		)


	@crew
	def crew(self) -> Crew:
		"""Creates the TransitToNatalReviewCrew crew"""
		# To learn how to add knowledge sources to your crew, check out the documentation:
		# https://docs.crewai.com/concepts/knowledge#what-is-knowledge

		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True
		)


File: 
main.py
Content: 
import os
import json
from datetime import datetime
from typing import Tuple
from crewai.flow import Flow, listen, start, and_
from transit_reader.utils.models import TransitState
from transit_reader.utils.qdrant_setup import Setup
from transit_reader.utils.immanuel_transit_chart import get_transit_chart
from transit_reader.utils.immanuel_natal_chart import get_natal_chart
from transit_reader.utils.immanuel_natal_to_transit_chart import get_transit_natal_aspects
from transit_reader.utils.kerykeion_chart_utils import get_kerykeion_subject, get_kerykeion_transit_chart
from transit_reader.utils.convert_to_pdf import convert_md_to_pdf
from transit_reader.utils.constants import NOW_DT, OUTPUT_DIR, TIMESTAMP, CHARTS_DIR
from transit_reader.crews.transit_analysis_crew.transit_analysis_crew import TransitAnalysisCrew
from transit_reader.crews.transit_analysis_review_crew.transit_analysis_review_crew import TransitAnalysisReviewCrew
from transit_reader.crews.natal_analysis_crew.natal_analysis_crew import NatalAnalysisCrew
from transit_reader.crews.natal_analysis_review_crew.natal_analysis_review_crew import NatalAnalysisReviewCrew
from transit_reader.crews.transit_to_natal_analysis_crew.transit_to_natal_analysis_crew import TransitToNatalAnalysisCrew
from transit_reader.crews.transit_to_natal_review_crew.transit_to_natal_review_crew import TransitToNatalReviewCrew
from transit_reader.crews.report_writing_crew.report_writing_crew import ReportWritingCrew
from transit_reader.crews.review_crew.review_crew import ReviewCrew
from transit_reader.crews.gmail_crew.gmail_crew import GmailCrew


class TransitFlow(Flow[TransitState]):

    @start()
    def setup_qdrant(self):
        print("Setting up Qdrant")
        setup = Setup(self.state)
        setup.process_new_markdown_files()


    @listen(setup_qdrant)
    def generate_current_transits(self):
        print("Generating current transits")
        current_location: Tuple[float, float] = (
            self.state.current_location_latitude,
            self.state.current_location_longitude
        )
        
        self.state.current_transits = get_transit_chart(current_location[0], current_location[1])
    

    @listen(generate_current_transits)
    def generate_transit_analysis(self):
        print("Generating transit analysis")
        inputs = {
            "current_transits": self.state.current_transits,
            "name": self.state.name,
            "today": self.state.today,
            "location": self.state.current_location
        }

        transit_analysis = (
            TransitAnalysisCrew()
            .crew()
            .kickoff(inputs=inputs)
        )

        self.state.transit_analysis = transit_analysis.raw


    @listen(generate_transit_analysis)
    def review_transit_analysis(self):
        print("Reviewing transit analysis")
        inputs = {
            "transit_analysis": self.state.transit_analysis,
            "current_transits": self.state.current_transits,
            "today": self.state.today,
            "name": self.state.name,
            "location": self.state.current_location
        }

        enhanced_transit_analysis = (
            TransitAnalysisReviewCrew()
            .crew()
            .kickoff(inputs=inputs)
        )

        self.state.transit_analysis = enhanced_transit_analysis.raw


    @listen(review_transit_analysis)
    def get_natal_chart_data(self):
        print("Getting natal chart data")
        natal_chart = get_natal_chart(self.state.date_of_birth, self.state.birthplace_latitude, self.state.birthplace_longitude)
        self.state.natal_chart = natal_chart
    

    @listen(get_natal_chart_data)
    def generate_natal_analysis(self):
        print("Generating natal analysis")

        inputs = {
            "natal_chart": self.state.natal_chart,
            "name": self.state.name,
            "date_of_birth": self.state.dob,
            "birthplace": self.state.birthplace,
            "today": self.state.today
        }
        
        natal_analysis = (
            NatalAnalysisCrew()
            .crew()
            .kickoff(inputs=inputs)
        )

        self.state.natal_analysis = natal_analysis.raw

    
    @listen(generate_natal_analysis)
    def review_natal_analysis(self):
        print("Reviewing natal analysis")
        inputs = {
            "natal_analysis": self.state.natal_analysis,
            "natal_chart": self.state.natal_chart,
            "name": self.state.name,
            "today": self.state.today,
            "date_of_birth": self.state.dob,
            "birthplace": self.state.birthplace
        }

        enhanced_natal_analysis = (
            NatalAnalysisReviewCrew()
            .crew()
            .kickoff(inputs=inputs)
        )

        self.state.natal_analysis = enhanced_natal_analysis.raw

    
    @listen(review_natal_analysis)
    def get_transit_to_natal_chart_data(self):
        print("Getting transit to natal chart data")
        transit_to_natal_chart = get_transit_natal_aspects(
            self.state.current_location_latitude,
            self.state.current_location_longitude,
            self.state.date_of_birth,
            self.state.birthplace_latitude,
            self.state.birthplace_longitude
        )

        self.state.transit_to_natal_chart = transit_to_natal_chart


    @listen(get_transit_to_natal_chart_data)
    def generate_transit_to_natal_analysis(self):
        print("Generating transit to natal analysis")
        inputs = {
            "transit_to_natal_chart": self.state.transit_to_natal_chart,
            "name": self.state.name,
            "today": self.state.today,
            "date_of_birth": self.state.dob,
            "birthplace": self.state.birthplace,
            "current_location": self.state.current_location
        }

        transit_to_natal_analysis = (
            TransitToNatalAnalysisCrew()
            .crew()
            .kickoff(inputs=inputs)
        )

        self.state.transit_to_natal_analysis = transit_to_natal_analysis.raw


    @listen(generate_transit_to_natal_analysis)
    def review_transit_to_natal_analysis(self):
        print("Reviewing transit to natal analysis")

        inputs = {
            "transit_to_natal_analysis": self.state.transit_to_natal_analysis,
            "transit_to_natal_chart": self.state.transit_to_natal_chart,
            "name": self.state.name,
            "today": self.state.today,
            "date_of_birth": self.state.dob,
            "birthplace": self.state.birthplace,
            "current_location": self.state.current_location
        }

        enhanced_transit_to_natal_analysis = (
            TransitToNatalReviewCrew()
            .crew()
            .kickoff(inputs=inputs)
        )

        self.state.transit_to_natal_analysis = enhanced_transit_to_natal_analysis.raw


    @listen(review_transit_to_natal_analysis)
    def generate_report_draft(self):
        print("Generating report draft")
        inputs = {
            "transit_analysis": self.state.transit_analysis,
            "natal_analysis": self.state.natal_analysis,
            "transit_to_natal_analysis": self.state.transit_to_natal_analysis,
            "name": self.state.name,
            "today": self.state.today,
            "location": self.state.current_location,
            "date_of_birth": self.state.dob,
            "birthplace": self.state.birthplace,
            "current_location": self.state.current_location
        }

        report_draft = (
            ReportWritingCrew()
            .crew()
            .kickoff(inputs=inputs)
        )

        self.state.report_markdown = report_draft.raw


    @listen(generate_report_draft)
    def interrogate_report_draft(self):
        print("Interrogating report draft")

        inputs = {
            "report": self.state.report_markdown,
            "transit_analysis": self.state.transit_analysis,
            "natal_analysis": self.state.natal_analysis,
            "transit_to_natal_analysis": self.state.transit_to_natal_analysis,
            "transit_chart": self.state.current_transits,
            "natal_chart": self.state.natal_chart,
            "transit_to_natal_chart": self.state.transit_to_natal_chart,
            "today": self.state.today,
            "name": self.state.name,
            "location": self.state.current_location,
            "date_of_birth": self.state.dob,
            "birthplace": self.state.birthplace
        }

        enhanced_report_draft = (
            ReviewCrew()
            .crew()
            .kickoff(inputs=inputs)
        )

        self.state.report_markdown = enhanced_report_draft.raw
        

    @listen(interrogate_report_draft)
    def generate_kerykeion_transit_chart(self):
        print("Generating kerykeion transit chart")
        
        main_subject = get_kerykeion_subject(
            self.state.name,
            self.state.date_of_birth.year,
            self.state.date_of_birth.month,
            self.state.date_of_birth.day,
            self.state.date_of_birth.hour,
            self.state.date_of_birth.minute,
            self.state.birthplace_city,
            self.state.birthplace_country,
            self.state.birthplace_longitude,
            self.state.birthplace_latitude,
            self.state.birthplace_timezone
        )

        transit_subject = get_kerykeion_subject(
            "Current transits",
            NOW_DT.year,
            NOW_DT.month,
            NOW_DT.day,
            NOW_DT.hour,
            NOW_DT.minute,
            self.state.current_location_city,
            self.state.current_location_country,
            self.state.current_location_longitude,
            self.state.current_location_latitude,
            self.state.current_location_timezone
        )
        
        kerykeion_transit_chart = get_kerykeion_transit_chart(main_subject, transit_subject, CHARTS_DIR)
        
        self.state.kerykeion_transit_chart = kerykeion_transit_chart


    @listen(generate_kerykeion_transit_chart)
    def save_transit_analysis(self):
        print("Saving transit analysis")
        markdown_file_path = OUTPUT_DIR / f"{self.state.name.replace(' ', '_')}_{TIMESTAMP}.md"

        self.state.report_markdown = self.state.report_markdown.replace("[transit_chart]", f"![Transit Chart]({self.state.kerykeion_transit_chart})")
        with open(markdown_file_path, "w") as f:
            f.write(self.state.report_markdown)

        print(f"Final report markdown saved to {markdown_file_path}")

        pdf_file_path = convert_md_to_pdf(markdown_file_path)
        self.state.report_pdf = pdf_file_path
        print(f"Report pdf saved to {pdf_file_path}")


    @listen(save_transit_analysis)
    def send_transit_analysis(self):
        print("Drafting email...")

        try:
            token_file_path = "src/transit_reader/utils/token.json"
            with open(token_file_path, "r") as f:
                token_data = json.load(f)
                expiry_date = token_data.get("expiry")
                if expiry_date:
                    expiry_date = datetime.fromisoformat(expiry_date)
                    if expiry_date < NOW_DT:
                        print("Token expired. Re-authentication required.")
                        os.remove(token_file_path)

        except FileNotFoundError:
            print("Token file not found. Re-authentication required.")
        except json.JSONDecodeError:
            print("Error decoding token file. Re-authentication required.")
            os.remove(token_file_path)
        except Exception as e:
            print(f"Unexpected error: {str(e)}")


        inputs = {
            "report_text": self.state.transit_analysis,
            "report_pdf": str(self.state.report_pdf),
            "client": self.state.name,
            "sender": "Ben Jasper",
            "email_address": self.state.email,
            "today": self.state.today
        }

        email_result = (
            GmailCrew()
            .crew()
            .kickoff(inputs=inputs)
        )

        if email_result.raw:
            print("Email draft complete")
        else:
            print("Email draft failed")


def kickoff():
    transit_flow = TransitFlow()
    transit_flow.kickoff()


def plot():
    transit_flow = TransitFlow()
    transit_flow.plot()


if __name__ == "__main__":
    kickoff()


File: 
tools/__init__.py
Content: 


File: 
tools/custom_tool.py
Content: 
from typing import Type

from crewai.tools import BaseTool
from pydantic import BaseModel, Field


class MyCustomToolInput(BaseModel):
    """Input schema for MyCustomTool."""

    argument: str = Field(..., description="Description of the argument.")


class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = (
        "Clear description for what this tool is useful for, your agent will need this information to use it."
    )
    args_schema: Type[BaseModel] = MyCustomToolInput

    def _run(self, argument: str) -> str:
        # Implementation goes here
        return "this is an example of a tool output, ignore it and move along."


File: 
tools/gemini_search_tool.py
Content: 
from typing import Type
from google import genai
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
import os

gemini_api_key = os.environ.get("GEMINI_API_KEY")

client = genai.Client(api_key=gemini_api_key, http_options={'api_version': 'v1alpha'})

MODEL = 'gemini-2.5-flash-preview-04-17'


class GeminiSearchToolInput(BaseModel):
    """Input schema for GeminiSearchTool."""

    query: str = Field(..., description="The query to search the web for.")


class GeminiSearchTool(BaseTool):
    name: str = "Gemini Search Tool"
    description: str = (
        "Use this tool to get Gemini-curated web search results for a given query. Provide a natural language query as a single string."
    )
    args_schema: Type[BaseModel] = GeminiSearchToolInput

    def _run(self, query: str) -> str:
        search_tool = {'google_search': {}}
        chat = client.chats.create(model=MODEL, config={'tools': [search_tool]})

        r = chat.send_message(query)

        return r.text
    

if __name__ == "__main__":
    query = "What are the latest Prewmier League results of today?"
    tool = GeminiSearchTool()
    print(tool.run(query))


File: 
tools/gmail_tool_with_attachment.py
Content: 
import os
from typing import Type

from crewai.tools import BaseTool
from pydantic import BaseModel, Field

from transit_reader.utils.gmail_utility_with_attachment import authenticate_gmail, gmail_create_draft_with_attachment

from dotenv import load_dotenv
load_dotenv()

class GmailAttachmentToolInput(BaseModel):
    """Input schema for GmailAttachmentToolInput."""

    body: str = Field(..., description="The body of the email to send.")
    subject: str = Field(..., description="The subject of the email to send.")
    attachment_filename: str = Field(..., description="The filename of the attachment to send.")

class GmailAttachmentTool(BaseTool):
    name: str = "GmailAttachmentTool"
    description: str = (
        "Send an email using the provided subject, body, and attachment filename"
    )
    args_schema: Type[BaseModel] = GmailAttachmentToolInput

    def _run(self, body: str, subject: str, attachment_filename: str) -> str:
        try:
            service = authenticate_gmail()
            sender = os.getenv("SENDER_EMAIL")
            to = os.getenv("CLIENT_EMAIL")
            subject = subject
            draft = gmail_create_draft_with_attachment(sender, to, subject, body, attachment_filename)

            if draft:
                return f"Email draft created successfully! Draft ID: {draft['id']}"
            else:
                return "Email draft creation failed."

        except Exception as e:
            return f"An error occurred: {e}"
        
if __name__ == "__main__":
    gmail_tool = GmailAttachmentTool()

    report = "/home/j/ai/crewAI/finance/stock_analyser/final_reports/2025-03-12/MSFT_Stock_Analysis_Report_20250312_132728.md"
    report_pdf = "/home/j/ai/crewAI/finance/stock_analyser/final_reports/2025-03-12/MSFT_Stock_Analysis_Report_20250312_132728.pdf"

    with open(report, "r") as file:
        body = file.read()

    print(gmail_tool.run(body=body, subject="Test Email", attachment_filename=report_pdf))
        

File: 
tools/linkup_search_tool.py
Content: 
import os
from typing import Type
from linkup import LinkupClient
from crewai.tools import BaseTool
from pydantic import BaseModel, Field


class LinkUpSearchInput(BaseModel):
    """Input schema for LinkUp Search Tool."""
    query: str = Field(description="The search query to perform")
    depth: str = Field(default="standard",
                       description="Depth of search: 'standard' or 'deep'")
    output_type: str = Field(
        default="searchResults", description="Output type: 'searchResults', 'sourcedAnswer', or 'structured'")


class LinkUpSearchTool(BaseTool):
    name: str = "LinkUp Search"
    description: str = "Search the web for information using LinkUp and return comprehensive results"
    args_schema: Type[BaseModel] = LinkUpSearchInput

    def __init__(self):
        super().__init__()

    def _run(self, query: str, depth: str = "standard", output_type: str = "searchResults") -> str:
        """Execute LinkUp search and return results."""
        try:
            # Initialize LinkUp client with API key from environment variables
            linkup_client = LinkupClient(api_key=os.getenv("LINKUP_API_KEY"))

            # Perform search
            search_response = linkup_client.search(
                query=query,
                depth=depth,
                output_type=output_type
            )

            return str(search_response)
        except Exception as e:
            return f"Error occurred while searching: {str(e)}"


if __name__ == "__main__":
    tool = LinkUpSearchTool()
    print(tool.run(query="What is the Opening Range Breakout trading strategy?"))


File: 
tools/qdrant_search_tool.py
Content: 
import os
from typing import Any, Optional, Type
from dotenv import load_dotenv
from pydantic import BaseModel, Field, ConfigDict

load_dotenv()

try:
    from qdrant_client import QdrantClient
    from qdrant_client.http.models import Filter, FieldCondition, MatchValue

    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False
    QdrantClient = Any  # type placeholder
    Filter = Any
    FieldCondition = Any
    MatchValue = Any

from crewai.tools import BaseTool


class QdrantSearchToolSchema(BaseModel):
    """Input for QdrantSearchTool."""

    query: str = Field(
        ...,
        description="The word or phrase to search for in the astrology reference docs. Must be a single string to match on similarity.",
    )
    # filter_by: Optional[str] = Field(
    #     default=None,
    #     description="Optional: The name of the metadata field to filter by (e.g., 'source').",
    # )
    # filter_value: Optional[str] = Field(
    #     default=None,
    #     description="Optional: The value to match for the filter_by field (e.g., 'AAPL_10-K.md').",
    # )


class QdrantSearchTool(BaseTool):
    """
    Custom tool to search a Qdrant database for relevant information,
    specifically designed for the 'stock_knowledge' collection.
    """
    model_config = {"arbitrary_types_allowed": True}
    client: QdrantClient = None
    name: str = "QdrantSearchTool"
    description: str = (
        "A tool to search astrology reference docs for relevant information"
    )
    args_schema: Type[BaseModel] = QdrantSearchToolSchema
    collection_name: str = Field(
        default=os.environ.get("QDRANT_COLLECTION_NAME"), description="Name of the Qdrant collection to search."
    )
    limit: int = Field(default=5, description="Maximum number of results to return.")
    score_threshold: float = Field(
        default=0.2, description="Minimum similarity score threshold."
    )
    qdrant_url: Optional[str] = Field(
        default=None, description="The URL of the Qdrant server."
    )
    qdrant_api_key: Optional[str] = Field(
        default=None, description="The API key for the Qdrant server."
    )
    custom_embedding_fn: Optional[callable] = Field(
        default=None,
        description="Optional custom embedding function. Defaults to Gemini embeddings.",
    )
    model_config = ConfigDict(arbitrary_types_allowed=True)


    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.qdrant_url = os.environ.get("QDRANT_CLUSTER_URL")
        self.qdrant_api_key = os.environ.get("QDRANT_API_KEY")
        self.collection_name = os.environ.get(
            "QDRANT_COLLECTION_NAME", "astro_knowledge"
        )  # Use env, fallback to default

        if not self.qdrant_url or not self.qdrant_api_key:
            raise ValueError(
                "QDRANT_CLUSTER_URL and QDRANT_API_KEY must be set as environment variables."
            )

        if QDRANT_AVAILABLE:
            self.client = QdrantClient(url=self.qdrant_url, api_key=self.qdrant_api_key)
        else:
            raise ImportError(
                "The 'qdrant-client' package is required.  Install it with: pip install qdrant-client"
            )

    def _run(
        self,
        query: str,
        # filter_by: Optional[str] = None,
        # filter_value: Optional[str] = None,
    ) -> str:
        """Execute vector similarity search on Qdrant."""

        if not self.client:
            return "Qdrant client not initialized."

        search_filter = None
        # if filter_by and filter_value:
        #     search_filter = Filter(
        #         must=[FieldCondition(key=filter_by, match=MatchValue(value=filter_value))]
        #     )

        try:
            if self.custom_embedding_fn:
                query_vector = self.custom_embedding_fn(query)
            else:
                # Use the custom Gemini embedding function from utils
                from transit_reader.utils.embeddings_fn import (
                    custom_gemini_embedding_fn,
                )

                query_vector = custom_gemini_embedding_fn(query)

            if query_vector is None:
                return "Error: Could not generate embedding for the query."

            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                query_filter=search_filter,
                limit=self.limit,
                score_threshold=self.score_threshold,
            )

            results = []
            for point in search_results:
                results.append(
                    {
                        "metadata": point.payload.get("source", ""),
                        "context": point.payload.get("text", ""),
                        "score": point.score,
                    }
                )
            return str(results)

        except Exception as e:
            return f"Error during Qdrant search: {e}"


if __name__ == "__main__":
    from dotenv import load_dotenv

    load_dotenv()
    # Example usage with dummy environment variables
    os.environ["QDRANT_CLUSTER_URL"] = os.environ.get("QDRANT_CLUSTER_URL")  # your qdrant url
    os.environ["QDRANT_API_KEY"] = os.environ.get("QDRANT_API_KEY")  # your qdrant api key
    os.environ["GEMINI_API_KEY"] = os.environ.get("GEMINI_API_KEY") # your gemini api key

    if (
        not os.environ.get("QDRANT_CLUSTER_URL")
        or not os.environ.get("QDRANT_API_KEY")
        or not os.environ.get("GEMINI_API_KEY")
    ):
        print(
            "Please set QDRANT_CLUSTER_URL, QDRANT_API_KEY and GEMINI_API_KEY environment variables."
        )
        exit(1)

    tool = QdrantSearchTool()
    query = "What is the ruler of the 1st house?"
    result = tool._run(query=query)
    print(result) 

File: 
utils/__init__.py
Content: 


File: 
utils/constants.py
Content: 
from datetime import datetime
from pathlib import Path

NOW_DT: datetime = datetime.now()
NOW: str = NOW_DT.strftime("%Y-%m-%d %H-%M")
TIMESTAMP: str = NOW_DT.strftime("%Y-%m-%d_%H-%M-%S")
DATE_TODAY: str = NOW_DT.strftime("%Y-%m-%d")
TODAY: str = NOW_DT.strftime("%A, %d %B %Y")

OUTPUT_DIR = Path(f'/home/j/ai/crewAI/astro/transit_reader_II/transit_reader/outputs/{DATE_TODAY}')
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

CREW_OUTPUTS_DIR = Path(f'/home/j/ai/crewAI/astro/transit_reader_II/transit_reader/crew_outputs/{TIMESTAMP}')
CREW_OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)

CHARTS_DIR = OUTPUT_DIR / 'charts'
CHARTS_DIR.mkdir(parents=True, exist_ok=True)

DOCS_DIR = Path("/home/j/ai/crewAI/astro/transit_reader_II/transit_reader/astro_docs")
DOCS_DIR.mkdir(parents=True, exist_ok=True)

SUBJECT_DIR = Path(__file__).parent.parent / "subjects"
SUBJECT_DIR.mkdir(parents=True, exist_ok=True)

CSS_FILE = Path('/home/j/ai/crewAI/astro/transit_reader_II/transit_reader/src/transit_reader/utils/astro_styling.css')




File: 
utils/convert_to_pdf.py
Content: 
from md2pdf.core import md2pdf
from pathlib import Path
from transit_reader.utils.constants import CSS_FILE, CHARTS_DIR

def convert_md_to_pdf(md_file_path: Path) -> Path:
    """Convert a markdown file to a PDF file."""
    pdf_file_path = Path(md_file_path).with_suffix('.pdf')

    md2pdf(pdf_file_path,
           md_file_path=md_file_path,
           base_url=CHARTS_DIR,
           css_file_path=CSS_FILE
    )

    return pdf_file_path


if __name__ == "__main__":
    md = '/home/j/ai/crewAI/astro/transit_reader_II/transit_reader/outputs/2025-04-18/Benjamin_Jasper_2025-04-18_20-58-23.md'
    pdf = convert_md_to_pdf(md)
    print(f"PDF file saved to {pdf}")

File: 
utils/embeddings_fn.py
Content: 
from google import genai
from dotenv import load_dotenv
import os

load_dotenv()

def custom_gemini_embedding_fn(text):
    """Generate embeddings for text using Gemini API."""

    gemini_api_key = os.getenv("GEMINI_API_KEY")

    genai_client = genai.Client(api_key=gemini_api_key)

    try:
        if not genai_client:
            print("❌ Gemini client not initialized. Cannot generate embeddings.")
            return None

        result = genai_client.models.embed_content(
            model="text-embedding-004",
            contents=text
        )
        # Extract the list of floats from the embeddings object
        if result and result.embeddings and result.embeddings[0].values :
          return result.embeddings[0].values
        else:
          print ("❌ Gemini embedding values are empty")
          return None

    except Exception as e:
        print(f"❌ Error generating embedding: {e}")
        return None

File: 
utils/gmail_utility_with_attachment.py
Content: 
import base64
import mimetypes
import os
from email.mime.audio import MIMEAudio
from email.mime.base import MIMEBase
from email.mime.image import MIMEImage
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email import encoders  # Import the encoders module

import google.auth
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import markdown


SCOPES = ['https://www.googleapis.com/auth/gmail.compose']

def authenticate_gmail():
    """
    Authenticate and return an authorized Gmail API service instance.
    Expects credentials.json and token.json in the same directory as this script.
    """
    current_dir = os.path.dirname(os.path.abspath(__file__))
    token_path = os.path.join(current_dir, 'token.json')
    credentials_path = os.path.join(current_dir, 'credentials.json')
    
    creds = None
    if os.path.exists(token_path):
        creds = Credentials.from_authorized_user_file(token_path, SCOPES)
    
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            if not os.path.exists(credentials_path):
                raise FileNotFoundError(
                    f"credentials.json not found at {credentials_path}. "
                    "Download OAuth 2.0 credentials from Google Cloud Console."
                )
            flow = InstalledAppFlow.from_client_secrets_file(credentials_path, SCOPES)
            creds = flow.run_local_server(port=0)
        with open(token_path, 'w') as token:
            token.write(creds.to_json())
    
    service = build('gmail', 'v1', credentials=creds)
    return service

def gmail_create_draft_with_attachment(sender: str, to: str, subject: str, markdown_text: str, attachment_filename: str) -> dict:
    """
    Create and insert a draft email with attachment.

    Args:
        sender: The email address of the sender.
        to: The email address of the recipient.
        subject: The subject of the email.
        markdown_text: The body of the email in markdown format.
        attachment_filename: The full path to the attachment file.

    Returns:
        Draft object, including draft id and message meta data, or None if an error occurs.
    """
    try:
        service = authenticate_gmail()  # Use the authentication function

        # Convert markdown to HTML
        md = markdown.Markdown(extensions=['tables', 'fenced_code'])
        html_content = md.convert(markdown_text)

        # Wrap the converted HTML in a full HTML document
        html = f"""\
<html>
  <head>
    <style>
      body {{
          font-family: Arial, sans-serif;
          line-height: 1.6;
          color: #333;
          max-width: 800px;
          margin: 0 auto;
          padding: 20px;
      }}
      h1 {{
          color: #2c3e50;
          border-bottom: 2px solid #eee;
          padding-bottom: 10px;
      }}
    </style>
  </head>
  <body>
    {html_content}
  </body>
</html>
"""
        # Create a multipart message
        message = MIMEMultipart()
        message["Subject"] = subject
        message["From"] = sender
        message["To"] = to

        # Attach the HTML content as the main part
        message.attach(MIMEText(html, "html"))

        # Attachment handling
        content_type, encoding = mimetypes.guess_type(attachment_filename)
        if content_type is None or encoding is not None:
            content_type = "application/octet-stream"
        main_type, sub_type = content_type.split("/", 1)

        try:
            with open(attachment_filename, "rb") as fp:
                if main_type == "text":
                    msg = MIMEText(fp.read().decode(), _subtype=sub_type)
                elif main_type == "image":
                    msg = MIMEImage(fp.read(), _subtype=sub_type)
                elif main_type == "audio":
                    msg = MIMEAudio(fp.read(), _subtype=sub_type)
                else:
                    msg = MIMEBase(main_type, sub_type)
                    file_content = fp.read()  # Read as bytes
                    msg.set_payload(file_content)
                    # Encode the payload correctly for binary data
                    encoders.encode_base64(msg) # Correct way to encode base64

                filename = os.path.basename(attachment_filename)
                msg.add_header("Content-Disposition", "attachment", filename=filename)
                message.attach(msg)
        except FileNotFoundError:
            print(f"Warning: Could not find attachment file: {attachment_filename}")
            #  Continue creating the draft *without* the attachment
        except Exception as e:
            print(f"An unexpected error occurred while processing the attachment: {e}")
            return None


        encoded_message = base64.urlsafe_b64encode(message.as_bytes()).decode()
        create_draft_request_body = {"message": {"raw": encoded_message}}
        draft = (
            service.users()
            .drafts()
            .create(userId="me", body=create_draft_request_body)
            .execute()
        )
        print(f'Draft id: {draft["id"]}\nDraft message: {draft["message"]}')
        return draft

    except HttpError as error:
        print(f"An error occurred: {error}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None


def create_draft(service, user_id: str, message_body: dict) -> dict:
    """
    Create and insert a draft email using the Gmail API.  (Moved from gmail_utility_inline_images_bup.py)

    Args:
        service: Authorized Gmail API service instance
        user_id: User's email address or 'me'
        message_body: Dict containing the raw base64url encoded message

    Returns:
        Created draft object or None if error occurs
    """
    try:
        draft = service.users().drafts().create(
            userId=user_id,
            body={'message': message_body}
        ).execute()
        print(f"Draft id: {draft['id']}")
        return draft
    except Exception as error:
        print(f"An error occurred while creating draft: {error}")
        return None


# Removed the build_file_part function as it's now integrated into gmail_create_draft_with_attachment

if __name__ == "__main__":
    # Example Usage (replace with your actual values)
    sender_email = os.getenv("SENDER_EMAIL")  # Replace with your sender email
    recipient_email = os.getenv("SENDER_EMAIL")  # Replace with recipient email
    test_subject = "Test Email with Attachment and HTML"
    test_markdown = """
# This is a test email

This email includes:

*   A list
*   Some **bold** text
*   A [link](https://www.google.com)
    """
    test_attachment = "/home/j/ai/crewAI/finance/stock_analyser/final_reports/2025-03-17/SOUN_Stock_Analysis_Report_20250317_183922_orig.pdf"  # Replace with your attachment path

    # You'll need a credentials.json file for authentication.
    # See the Google API documentation for how to obtain this.

    if not os.path.exists(test_attachment):
        print("Creating dummy attachment file...")
        with open(test_attachment, "w") as f:
            f.write("Dummy PDF content")

    draft = gmail_create_draft_with_attachment(
        sender_email, recipient_email, test_subject, test_markdown, test_attachment
    )

    if draft:
        print(f"Draft created successfully! Draft ID: {draft['id']}")

File: 
utils/immanuel_natal_chart.py
Content: 
import json
from immanuel import charts
from immanuel.const import chart
from immanuel.setup import settings
from immanuel.classes.serialize import ToJSON
from datetime import datetime
from pathlib import Path

# settings.objects.append(chart.PHOLUS)
# settings.objects.append(chart.CERES)
# settings.objects.append(chart.PALLAS)
# settings.objects.append(chart.JUNO)
# settings.objects.append(chart.VESTA)
# settings.objects.append(chart.NORTH_NODE)
# settings.objects.append(chart.SOUTH_NODE)
settings.objects.append(chart.TRUE_NORTH_NODE)
settings.objects.append(chart.TRUE_SOUTH_NODE)
# settings.objects.append(chart.VERTEX)
settings.objects.append(chart.LILITH)
# settings.objects.append(chart.TRUE_LILITH)
# settings.objects.append(chart.INTERPOLATED_LILITH)
# settings.objects.append(chart.SYZYGY)
# settings.objects.append(chart.PART_OF_FORTUNE)
# settings.objects.append(chart.PART_OF_SPIRIT)
# settings.objects.append(chart.PART_OF_EROS)
# settings.objects.append(chart.PRE_NATAL_SOLAR_ECLIPSE)
# settings.objects.append(chart.PRE_NATAL_LUNAR_ECLIPSE)
# settings.objects.append(chart.POST_NATAL_SOLAR_ECLIPSE)
# settings.objects.append(chart.POST_NATAL_LUNAR_ECLIPSE)


def get_natal_chart(dob: datetime, latitude: float, longitude: float) -> str:
    subject = charts.Subject(dob, latitude, longitude)
    subject_natal = charts.Natal(subject)
    natal_data = json.dumps(subject_natal, cls=ToJSON, indent=4)
    chart_data = json.loads(natal_data)

    output_lines = []

    # --- 1. Native Information ---
    output_lines.append("--- Natal Chart Summary ---")
    native_info = chart_data.get("native", {})
    date_time_info = native_info.get("date_time", {})
    coords_info = native_info.get("coordinates", {})
    
    output_lines.append(f"Birth Date/Time: {date_time_info.get('datetime', 'N/A')} ({date_time_info.get('timezone', 'N/A')})")
    output_lines.append(f"Julian Day: {date_time_info.get('julian', 'N/A'):.5f}")
    output_lines.append(f"Sidereal Time: {date_time_info.get('sidereal_time', 'N/A')}")
    
    lat = coords_info.get("latitude", {})
    lon = coords_info.get("longitude", {})
    output_lines.append(f"Birth Location: Latitude {lat.get('formatted', 'N/A')}, Longitude {lon.get('formatted', 'N/A')}")
    output_lines.append("-" * 25) # Separator

    # --- 2. Chart Details ---
    output_lines.append("--- Chart Details ---")
    output_lines.append(f"House System: {chart_data.get('house_system', 'N/A')}")
    output_lines.append(f"Chart Shape: {chart_data.get('shape', 'N/A')}")
    output_lines.append(f"Diurnal/Nocturnal: {'Diurnal' if chart_data.get('diurnal', False) else 'Nocturnal'}")
    moon_phase_info = chart_data.get('moon_phase', {})
    output_lines.append(f"Moon Phase: {moon_phase_info.get('formatted', 'N/A')}")
    output_lines.append("-" * 25) # Separator

    # --- 3. Celestial Objects (Planets, Points, Angles, Asteroids) ---
    output_lines.append("--- Celestial Objects ---")
    # Sort objects for consistent order, maybe by a standard astrological order?
    # For now, just sort by name after Angles (Asc, Desc, MC, IC)
    angles = {k: v for k, v in chart_data['objects'].items() if v['type']['name'] == 'Angle'}
    others = {k: v for k, v in chart_data['objects'].items() if v['type']['name'] != 'Angle'}
    
    # Define a rough order for display
    display_order = [
        'Sun', 'Moon', 'Mercury', 'Venus', 'Mars', 'Jupiter', 'Saturn', 
        'Uranus', 'Neptune', 'Pluto', 'Chiron', 'True North Node', 
        'True South Node', 'Asc', 'MC', 'IC', 'Desc', 'Part of Fortune', 
        'Vertex', 'True Lilith' # Add others as needed
    ]
    
    # Create a map for lookup
    obj_by_name = {v['name']: v for v in chart_data['objects'].values()}
    sorted_objects = []
    processed_names = set()

    # Add objects in display_order first
    for name in display_order:
        if name in obj_by_name:
            sorted_objects.append(obj_by_name[name])
            processed_names.add(name)

    # Add any remaining objects not in the specific order, sorted by name
    remaining_objects = sorted(
        [v for name, v in obj_by_name.items() if name not in processed_names],
        key=lambda x: x['name']
    )
    sorted_objects.extend(remaining_objects)


    # Build a map for easy lookup by ID later (needed for aspects)
    object_map = {str(obj['index']): obj for obj in chart_data['objects'].values()}


    for obj in sorted_objects:
        obj_name = obj.get('name', 'Unknown Object')
        obj_type = obj.get('type', {}).get('name', 'N/A')
        output_lines.append(f"\n* {obj_name} ({obj_type})")

        sign_info = obj.get('sign', {})
        sign_name = sign_info.get('name', 'N/A')
        sign_element = sign_info.get('element', 'N/A')
        sign_modality = sign_info.get('modality', 'N/A')
        
        long_fmt = obj.get('longitude', {}).get('formatted', 'N/A')
        sign_long_fmt = obj.get('sign_longitude', {}).get('formatted', 'N/A')
        output_lines.append(f"  Position: {sign_long_fmt} {sign_name} ({sign_element}, {sign_modality})")
        output_lines.append(f"  Zodiac Longitude: {long_fmt}")

        house_info = obj.get('house', {})
        house_name = house_info.get('name', 'N/A')
        output_lines.append(f"  House: {house_name}")

        decan_info = obj.get('decan', {})
        decan_name = decan_info.get('name', 'N/A')
        output_lines.append(f"  Decan: {decan_name}")

        # Optional fields check
        if 'latitude' in obj:
            lat_fmt = obj['latitude'].get('formatted', 'N/A')
            output_lines.append(f"  Latitude: {lat_fmt}")
        
        decl_fmt = obj.get('declination', {}).get('formatted', 'N/A')
        output_lines.append(f"  Declination: {decl_fmt}" + (" (Out of Bounds)" if obj.get('out_of_bounds') else ""))

        if 'speed' in obj and 'movement' in obj:
            speed = obj.get('speed', 0.0)
            move_fmt = obj.get('movement', {}).get('formatted', 'N/A')
            output_lines.append(f"  Movement: {move_fmt} (Speed: {speed:.4f}°/day)") # Adjust precision as needed

        if 'distance' in obj:
            dist = obj.get('distance', 0.0)
            output_lines.append(f"  Distance: {dist:.4f} AU")

        if 'in_sect' in obj: # Only applies to traditional planets
            output_lines.append(f"  In Sect: {'Yes' if obj['in_sect'] else 'No'}")
            
        if 'dignities' in obj and obj['dignities'] and obj['dignities'].get('formatted'):
            dignities_str = ", ".join(obj['dignities']['formatted'])
            output_lines.append(f"  Dignities/Debilities: {dignities_str}")
            
        # Specific info for eclipses
        if obj_type == 'Eclipse':
             eclipse_type_info = obj.get('eclipse_type', {})
             eclipse_fmt = eclipse_type_info.get('formatted', 'N/A')
             eclipse_date_info = obj.get('date_time', {})
             eclipse_date = eclipse_date_info.get('datetime', 'N/A')
             output_lines.append(f"  Eclipse Type: {eclipse_fmt}")
             output_lines.append(f"  Eclipse Date: {eclipse_date}")


    output_lines.append("-" * 25) # Separator

    # --- 4. Houses ---
    output_lines.append("--- Houses (Cusps) ---")
    # Sort houses by number
    sorted_houses = sorted(chart_data['houses'].values(), key=lambda h: h['number'])
    
    for house in sorted_houses:
        house_name = house.get('name', 'Unknown House')
        output_lines.append(f"\n* {house_name} Cusp:")

        sign_info = house.get('sign', {})
        sign_name = sign_info.get('name', 'N/A')
        sign_element = sign_info.get('element', 'N/A')
        sign_modality = sign_info.get('modality', 'N/A')
        
        long_fmt = house.get('longitude', {}).get('formatted', 'N/A')
        sign_long_fmt = house.get('sign_longitude', {}).get('formatted', 'N/A')
        output_lines.append(f"  Position: {sign_long_fmt} {sign_name} ({sign_element}, {sign_modality})")
        output_lines.append(f"  Zodiac Longitude: {long_fmt}")
        
        size = house.get('size', 0.0)
        output_lines.append(f"  Size: {size:.2f}°") # Size of the house

    output_lines.append("-" * 25) # Separator

    # --- 5. Aspects ---
    output_lines.append("--- Aspects ---")
    processed_aspects = set() # To avoid printing duplicates like Sun-Moon and Moon-Sun

    # Iterate through all possible active objects that have aspects listed
    for active_id_str, passive_dict in chart_data.get('aspects', {}).items():
        # Iterate through all passive objects aspected by the active one
        for passive_id_str, aspect_details in passive_dict.items():
            
            # Create a unique identifier for the pair, regardless of order
            # Convert IDs to strings ensures consistent sorting if one is int and other str
            pair = tuple(sorted((active_id_str, passive_id_str))) 

            if pair in processed_aspects:
                continue # Skip if we've already processed this pair

            processed_aspects.add(pair) # Mark this pair as processed

            # Get object names from the map created earlier
            active_obj = object_map.get(active_id_str)
            passive_obj = object_map.get(passive_id_str)

            if not active_obj or not passive_obj:
                continue # Should not happen with valid data, but safety check

            active_name = active_obj.get('name', f'ID {active_id_str}')
            passive_name = passive_obj.get('name', f'ID {passive_id_str}')
            
            aspect_type = aspect_details.get('type', 'N/A')
            orb = aspect_details.get('orb', 0.0)
            diff_fmt = aspect_details.get('difference', {}).get('formatted', 'N/A')
            move_fmt = aspect_details.get('movement', {}).get('formatted', 'N/A')
            cond_fmt = aspect_details.get('condition', {}).get('formatted', 'N/A') # Associate/Dissociate

            # Format the aspect line
            # Example: Sun Conjunction Moon (Orb: 5.23°, Diff: +05°14'02", Applying, Associate)
            output_lines.append(
                f"* {active_name} {aspect_type} {passive_name} "
                f"(Orb: {orb:.2f}°, Diff: {diff_fmt}, {move_fmt}, {cond_fmt})"
            )

    if not processed_aspects:
         output_lines.append("  (No major aspects listed or calculable in source data)")
         
    output_lines.append("-" * 25) # Separator

    # --- 6. Weightings (Elements, Modalities, Quadrants) ---
    output_lines.append("--- Chart Weightings ---")
    weightings = chart_data.get('weightings', {})
    
    # Elements
    output_lines.append("\nElements:")
    elements = weightings.get('elements', {})
    for element, obj_list in elements.items():
        output_lines.append(f"  {element.capitalize()}: {len(obj_list)} objects")
        # Optionally list objects: ", ".join([object_map[str(oid)]['name'] for oid in obj_list])

    # Modalities
    output_lines.append("\nModalities:")
    modalities = weightings.get('modalities', {})
    for modality, obj_list in modalities.items():
         output_lines.append(f"  {modality.capitalize()}: {len(obj_list)} objects")

    # Quadrants
    output_lines.append("\nQuadrants (based on object count):")
    quadrants = weightings.get('quadrants', {})
    quadrant_names = { # Map keys to descriptive names
         'first': 'First (Houses 1-3)', 
         'second': 'Second (Houses 4-6)', 
         'third': 'Third (Houses 7-9)', 
         'fourth': 'Fourth (Houses 10-12)'
    }
    for quadrant_key, obj_list in quadrants.items():
         quad_name = quadrant_names.get(quadrant_key, quadrant_key.capitalize())
         output_lines.append(f"  {quad_name}: {len(obj_list)} objects")

    output_lines.append("-" * 25) # Separator
    output_lines.append("--- End of Natal Chart ---")

    return "\n".join(output_lines)

if __name__ == "__main__":
    subject_data_file = Path(__file__).parent.parent / "subjects" / "benjamin_jasper.json"
    with open(subject_data_file, 'r') as f:
        subject_data = json.load(f)

    dob = datetime.strptime(subject_data.get('date_of_birth'), '%Y-%m-%d %H:%M:%S')
    latitude = subject_data['birthplace']['latitude']
    longitude = subject_data['birthplace']['longitude']
    
    natal_chart = get_natal_chart(dob, latitude, longitude)
    with open("natal_chart.txt", "w") as f:
        f.write(natal_chart)

File: 
utils/immanuel_natal_to_transit_chart.py
Content: 
import json
from immanuel import charts
from immanuel.const import chart
from immanuel.setup import settings
from immanuel.classes.serialize import ToJSON
from datetime import datetime
from pathlib import Path

# settings.objects.append(chart.PHOLUS)
# settings.objects.append(chart.CERES)
# settings.objects.append(chart.PALLAS)
# settings.objects.append(chart.JUNO)
# settings.objects.append(chart.VESTA)
# settings.objects.append(chart.NORTH_NODE)
# settings.objects.append(chart.SOUTH_NODE)
settings.objects.append(chart.TRUE_NORTH_NODE)
settings.objects.append(chart.TRUE_SOUTH_NODE)
# settings.objects.append(chart.VERTEX)
settings.objects.append(chart.LILITH)
# settings.objects.append(chart.TRUE_LILITH)
# settings.objects.append(chart.INTERPOLATED_LILITH)
# settings.objects.append(chart.SYZYGY)
# settings.objects.append(chart.PART_OF_FORTUNE)
# settings.objects.append(chart.PART_OF_SPIRIT)
# settings.objects.append(chart.PART_OF_EROS)
# settings.objects.append(chart.PRE_NATAL_SOLAR_ECLIPSE)
# settings.objects.append(chart.PRE_NATAL_LUNAR_ECLIPSE)
# settings.objects.append(chart.POST_NATAL_SOLAR_ECLIPSE)
# settings.objects.append(chart.POST_NATAL_LUNAR_ECLIPSE)



def get_transit_natal_aspects(location_latitude: float, location_longitude: float, dob: datetime, birthplace_latitude: float, birthplace_longitude: float) -> dict:
    subject = charts.Subject(dob, birthplace_latitude, birthplace_longitude)
    subject_natal = charts.Natal(subject)
    transit_date = datetime.now()
    transit_chart = charts.Transits(location_latitude, location_longitude, aspects_to=subject_natal)

    transit_data = json.dumps(transit_chart, cls=ToJSON, indent=4)
    chart_data = json.loads(transit_data)

    output_lines = []

    # --- 1. Native Information ---
    output_lines.append("--- Transit to Natal Chart Summary ---")
    native_info = chart_data.get("native", {})
    date_time_info = native_info.get("date_time", {})
    coords_info = native_info.get("coordinates", {})
    
    output_lines.append(f"Transit Date/Time: {transit_date.strftime('%A, %d %B %Y %H:%M:%S')}")
    output_lines.append(f"Julian Day: {date_time_info.get('julian', 'N/A'):.5f}")
    output_lines.append(f"Sidereal Time: {date_time_info.get('sidereal_time', 'N/A')}")

    lat = coords_info.get("latitude", {})
    lon = coords_info.get("longitude", {})
    output_lines.append(f"Transit Location: Latitude {lat.get('formatted', 'N/A')}, Longitude {lon.get('formatted', 'N/A')}")
    
    output_lines.append(f"Date of Birth: {dob.strftime('%A, %d %B %Y %H:%M:%S')}")
    output_lines.append(f"Birthplace: {birthplace_latitude}, {birthplace_longitude}")
    output_lines.append("-" * 25) # Separator

    # --- 2. Chart Details ---
    output_lines.append("--- Chart Details ---")
    output_lines.append(f"House System: {chart_data.get('house_system', 'N/A')}")
    output_lines.append(f"Chart Shape: {chart_data.get('shape', 'N/A')}")
    output_lines.append(f"Diurnal/Nocturnal: {'Diurnal' if chart_data.get('diurnal', False) else 'Nocturnal'}")
    moon_phase_info = chart_data.get('moon_phase', {})
    output_lines.append(f"Moon Phase: {moon_phase_info.get('formatted', 'N/A')}")
    output_lines.append("-" * 25) # Separator

    # --- 3. Celestial Objects (Planets, Points, Angles, Asteroids) ---
    output_lines.append("--- Celestial Objects ---")
    # Sort objects for consistent order, maybe by a standard astrological order?
    # For now, just sort by name after Angles (Asc, Desc, MC, IC)
    angles = {k: v for k, v in chart_data['objects'].items() if v['type']['name'] == 'Angle'}
    others = {k: v for k, v in chart_data['objects'].items() if v['type']['name'] != 'Angle'}
    
    # Define a rough order for display
    display_order = [
        'Sun', 'Moon', 'Mercury', 'Venus', 'Mars', 'Jupiter', 'Saturn', 
        'Uranus', 'Neptune', 'Pluto', 'Chiron', 'True North Node', 
        'True South Node', 'Asc', 'MC', 'IC', 'Desc', 'Part of Fortune', 
        'Vertex', 'True Lilith' # Add others as needed
    ]
    
    # Create a map for lookup
    obj_by_name = {v['name']: v for v in chart_data['objects'].values()}
    sorted_objects = []
    processed_names = set()

    # Add objects in display_order first
    for name in display_order:
        if name in obj_by_name:
            sorted_objects.append(obj_by_name[name])
            processed_names.add(name)

    # Add any remaining objects not in the specific order, sorted by name
    remaining_objects = sorted(
        [v for name, v in obj_by_name.items() if name not in processed_names],
        key=lambda x: x['name']
    )
    sorted_objects.extend(remaining_objects)


    # Build a map for easy lookup by ID later (needed for aspects)
    object_map = {str(obj['index']): obj for obj in chart_data['objects'].values()}


    for obj in sorted_objects:
        obj_name = obj.get('name', 'Unknown Object')
        obj_type = obj.get('type', {}).get('name', 'N/A')
        output_lines.append(f"\n* {obj_name} ({obj_type})")

        sign_info = obj.get('sign', {})
        sign_name = sign_info.get('name', 'N/A')
        sign_element = sign_info.get('element', 'N/A')
        sign_modality = sign_info.get('modality', 'N/A')
        
        long_fmt = obj.get('longitude', {}).get('formatted', 'N/A')
        sign_long_fmt = obj.get('sign_longitude', {}).get('formatted', 'N/A')
        output_lines.append(f"  Position: {sign_long_fmt} {sign_name} ({sign_element}, {sign_modality})")
        output_lines.append(f"  Zodiac Longitude: {long_fmt}")

        house_info = obj.get('house', {})
        house_name = house_info.get('name', 'N/A')
        output_lines.append(f"  House: {house_name}")

        decan_info = obj.get('decan', {})
        decan_name = decan_info.get('name', 'N/A')
        output_lines.append(f"  Decan: {decan_name}")

        # Optional fields check
        if 'latitude' in obj:
            lat_fmt = obj['latitude'].get('formatted', 'N/A')
            output_lines.append(f"  Latitude: {lat_fmt}")
        
        decl_fmt = obj.get('declination', {}).get('formatted', 'N/A')
        output_lines.append(f"  Declination: {decl_fmt}" + (" (Out of Bounds)" if obj.get('out_of_bounds') else ""))

        if 'speed' in obj and 'movement' in obj:
            speed = obj.get('speed', 0.0)
            move_fmt = obj.get('movement', {}).get('formatted', 'N/A')
            output_lines.append(f"  Movement: {move_fmt} (Speed: {speed:.4f}°/day)") # Adjust precision as needed

        if 'distance' in obj:
            dist = obj.get('distance', 0.0)
            output_lines.append(f"  Distance: {dist:.4f} AU")

        if 'in_sect' in obj: # Only applies to traditional planets
            output_lines.append(f"  In Sect: {'Yes' if obj['in_sect'] else 'No'}")
            
        if 'dignities' in obj and obj['dignities'] and obj['dignities'].get('formatted'):
            dignities_str = ", ".join(obj['dignities']['formatted'])
            output_lines.append(f"  Dignities/Debilities: {dignities_str}")
            
        # Specific info for eclipses
        if obj_type == 'Eclipse':
             eclipse_type_info = obj.get('eclipse_type', {})
             eclipse_fmt = eclipse_type_info.get('formatted', 'N/A')
             eclipse_date_info = obj.get('date_time', {})
             eclipse_date = eclipse_date_info.get('datetime', 'N/A')
             output_lines.append(f"  Eclipse Type: {eclipse_fmt}")
             output_lines.append(f"  Eclipse Date: {eclipse_date}")


    output_lines.append("-" * 25) # Separator

    # --- 4. Houses ---
    output_lines.append("--- Houses (Cusps) ---")
    # Sort houses by number
    sorted_houses = sorted(chart_data['houses'].values(), key=lambda h: h['number'])
    
    for house in sorted_houses:
        house_name = house.get('name', 'Unknown House')
        output_lines.append(f"\n* {house_name} Cusp:")

        sign_info = house.get('sign', {})
        sign_name = sign_info.get('name', 'N/A')
        sign_element = sign_info.get('element', 'N/A')
        sign_modality = sign_info.get('modality', 'N/A')
        
        long_fmt = house.get('longitude', {}).get('formatted', 'N/A')
        sign_long_fmt = house.get('sign_longitude', {}).get('formatted', 'N/A')
        output_lines.append(f"  Position: {sign_long_fmt} {sign_name} ({sign_element}, {sign_modality})")
        output_lines.append(f"  Zodiac Longitude: {long_fmt}")
        
        size = house.get('size', 0.0)
        output_lines.append(f"  Size: {size:.2f}°") # Size of the house

    output_lines.append("-" * 25) # Separator

    # --- 5. Aspects ---
    output_lines.append("--- Aspects ---")
    processed_aspects = set() # To avoid printing duplicates like Sun-Moon and Moon-Sun

    # Iterate through all possible active objects that have aspects listed
    for active_id_str, passive_dict in chart_data.get('aspects', {}).items():
        # Iterate through all passive objects aspected by the active one
        for passive_id_str, aspect_details in passive_dict.items():
            
            # Create a unique identifier for the pair, regardless of order
            # Convert IDs to strings ensures consistent sorting if one is int and other str
            pair = tuple(sorted((active_id_str, passive_id_str))) 

            if pair in processed_aspects:
                continue # Skip if we've already processed this pair

            processed_aspects.add(pair) # Mark this pair as processed

            # Get object names from the map created earlier
            active_obj = object_map.get(active_id_str)
            passive_obj = object_map.get(passive_id_str)

            if not active_obj or not passive_obj:
                continue # Should not happen with valid data, but safety check

            active_name = active_obj.get('name', f'ID {active_id_str}')
            passive_name = passive_obj.get('name', f'ID {passive_id_str}')
            
            aspect_type = aspect_details.get('type', 'N/A')
            orb = aspect_details.get('orb', 0.0)
            diff_fmt = aspect_details.get('difference', {}).get('formatted', 'N/A')
            move_fmt = aspect_details.get('movement', {}).get('formatted', 'N/A')
            cond_fmt = aspect_details.get('condition', {}).get('formatted', 'N/A') # Associate/Dissociate

            # Format the aspect line
            # Example: Sun Conjunction Moon (Orb: 5.23°, Diff: +05°14'02", Applying, Associate)
            output_lines.append(
                f"* {active_name} {aspect_type} {passive_name} "
                f"(Orb: {orb:.2f}°, Diff: {diff_fmt}, {move_fmt}, {cond_fmt})"
            )

    if not processed_aspects:
         output_lines.append("  (No major aspects listed or calculable in source data)")
         
    output_lines.append("-" * 25) # Separator

    # --- 6. Weightings (Elements, Modalities, Quadrants) ---
    output_lines.append("--- Chart Weightings ---")
    weightings = chart_data.get('weightings', {})
    
    # Elements
    output_lines.append("\nElements:")
    elements = weightings.get('elements', {})
    for element, obj_list in elements.items():
        output_lines.append(f"  {element.capitalize()}: {len(obj_list)} objects")
        # Optionally list objects: ", ".join([object_map[str(oid)]['name'] for oid in obj_list])

    # Modalities
    output_lines.append("\nModalities:")
    modalities = weightings.get('modalities', {})
    for modality, obj_list in modalities.items():
         output_lines.append(f"  {modality.capitalize()}: {len(obj_list)} objects")

    # Quadrants
    output_lines.append("\nQuadrants (based on object count):")
    quadrants = weightings.get('quadrants', {})
    quadrant_names = { # Map keys to descriptive names
         'first': 'First (Houses 1-3)', 
         'second': 'Second (Houses 4-6)', 
         'third': 'Third (Houses 7-9)', 
         'fourth': 'Fourth (Houses 10-12)'
    }
    for quadrant_key, obj_list in quadrants.items():
         quad_name = quadrant_names.get(quadrant_key, quadrant_key.capitalize())
         output_lines.append(f"  {quad_name}: {len(obj_list)} objects")

    output_lines.append("-" * 25) # Separator
    output_lines.append("--- End of Transit to Natal Chart ---")

    return "\n".join(output_lines)

if __name__ == "__main__":
    subject_data_file = Path(__file__).parent.parent / "subjects" / "benjamin_jasper.json"
    with open(subject_data_file, "r") as f:
        subject_data = json.load(f)

    location_longitude = subject_data["current_location"]["longitude"]
    location_latitude = subject_data["current_location"]["latitude"]
    dob = datetime.strptime(subject_data["date_of_birth"], "%Y-%m-%d %H:%M:%S")
    birthplace_longitude = subject_data["birthplace"]["longitude"]
    birthplace_latitude = subject_data["birthplace"]["latitude"]

    subject = charts.Subject(dob, birthplace_latitude, birthplace_longitude)
    subject_natal = charts.Natal(subject)
    transit_chart = charts.Transits(location_latitude, location_longitude, aspects_to=subject_natal)

    transit_data = json.dumps(transit_chart, cls=ToJSON, indent=4)
    with open("transit_to_natal_chart.json", "w") as f:
        f.write(transit_data)
    
    transit_chart = get_transit_natal_aspects(location_latitude, location_longitude, dob, birthplace_latitude, birthplace_longitude)
    with open("transit_chart.txt", "w") as f:
        f.write(transit_chart)
    
    print(f"Transit chart saved to transit_chart.txt")

File: 
utils/immanuel_transit_chart.py
Content: 
import json
from immanuel import charts
from immanuel.const import chart
from immanuel.setup import settings
from immanuel.classes.serialize import ToJSON
from datetime import datetime


# settings.objects.append(chart.PHOLUS)
# settings.objects.append(chart.CERES)
# settings.objects.append(chart.PALLAS)
# settings.objects.append(chart.JUNO)
# settings.objects.append(chart.VESTA)
# settings.objects.append(chart.NORTH_NODE)
# settings.objects.append(chart.SOUTH_NODE)
settings.objects.append(chart.TRUE_NORTH_NODE)
settings.objects.append(chart.TRUE_SOUTH_NODE)
# settings.objects.append(chart.VERTEX)
settings.objects.append(chart.LILITH)
# settings.objects.append(chart.TRUE_LILITH)
# settings.objects.append(chart.INTERPOLATED_LILITH)
# settings.objects.append(chart.SYZYGY)
# settings.objects.append(chart.PART_OF_FORTUNE)
# settings.objects.append(chart.PART_OF_SPIRIT)
# settings.objects.append(chart.PART_OF_EROS)
# settings.objects.append(chart.PRE_NATAL_SOLAR_ECLIPSE)
# settings.objects.append(chart.PRE_NATAL_LUNAR_ECLIPSE)
# settings.objects.append(chart.POST_NATAL_SOLAR_ECLIPSE)
# settings.objects.append(chart.POST_NATAL_LUNAR_ECLIPSE)


def get_transit_chart(latitude: float, longitude: float) -> str:
    transit_chart = charts.Transits(latitude, longitude)
    transit_data = json.dumps(transit_chart, cls=ToJSON, indent=4)
    chart_data = json.loads(transit_data)

    output_lines = []

    # --- 1. Native Information ---
    output_lines.append("--- Transit Chart Summary ---")
    native_info = chart_data.get("native", {})
    date_time_info = native_info.get("date_time", {})
    coords_info = native_info.get("coordinates", {})
    
    output_lines.append(f"Transit Date/Time: {datetime.now().strftime('%A, %d %B %Y %H:%M:%S')}")
    output_lines.append(f"Julian Day: {date_time_info.get('julian', 'N/A'):.5f}")
    output_lines.append(f"Sidereal Time: {date_time_info.get('sidereal_time', 'N/A')}")
    
    lat = coords_info.get("latitude", {})
    lon = coords_info.get("longitude", {})
    output_lines.append(f"Transit Location: Latitude {lat.get('formatted', 'N/A')}, Longitude {lon.get('formatted', 'N/A')}")
    output_lines.append("-" * 25) # Separator

    # --- 2. Chart Details ---
    output_lines.append("--- Chart Details ---")
    output_lines.append(f"House System: {chart_data.get('house_system', 'N/A')}")
    output_lines.append(f"Chart Shape: {chart_data.get('shape', 'N/A')}")
    output_lines.append(f"Diurnal/Nocturnal: {'Diurnal' if chart_data.get('diurnal', False) else 'Nocturnal'}")
    moon_phase_info = chart_data.get('moon_phase', {})
    output_lines.append(f"Moon Phase: {moon_phase_info.get('formatted', 'N/A')}")
    output_lines.append("-" * 25) # Separator

    # --- 3. Celestial Objects (Planets, Points, Angles, Asteroids) ---
    output_lines.append("--- Celestial Objects ---")
    # Sort objects for consistent order, maybe by a standard astrological order?
    # For now, just sort by name after Angles (Asc, Desc, MC, IC)
    angles = {k: v for k, v in chart_data['objects'].items() if v['type']['name'] == 'Angle'}
    others = {k: v for k, v in chart_data['objects'].items() if v['type']['name'] != 'Angle'}
    
    # Define a rough order for display
    display_order = [
        'Sun', 'Moon', 'Mercury', 'Venus', 'Mars', 'Jupiter', 'Saturn', 
        'Uranus', 'Neptune', 'Pluto', 'Chiron', 'True North Node', 
        'True South Node', 'Asc', 'MC', 'IC', 'Desc', 'Part of Fortune', 
        'Vertex', 'True Lilith' # Add others as needed
    ]
    
    # Create a map for lookup
    obj_by_name = {v['name']: v for v in chart_data['objects'].values()}
    sorted_objects = []
    processed_names = set()

    # Add objects in display_order first
    for name in display_order:
        if name in obj_by_name:
            sorted_objects.append(obj_by_name[name])
            processed_names.add(name)

    # Add any remaining objects not in the specific order, sorted by name
    remaining_objects = sorted(
        [v for name, v in obj_by_name.items() if name not in processed_names],
        key=lambda x: x['name']
    )
    sorted_objects.extend(remaining_objects)


    # Build a map for easy lookup by ID later (needed for aspects)
    object_map = {str(obj['index']): obj for obj in chart_data['objects'].values()}


    for obj in sorted_objects:
        obj_name = obj.get('name', 'Unknown Object')
        obj_type = obj.get('type', {}).get('name', 'N/A')
        output_lines.append(f"\n* {obj_name} ({obj_type})")

        sign_info = obj.get('sign', {})
        sign_name = sign_info.get('name', 'N/A')
        sign_element = sign_info.get('element', 'N/A')
        sign_modality = sign_info.get('modality', 'N/A')
        
        long_fmt = obj.get('longitude', {}).get('formatted', 'N/A')
        sign_long_fmt = obj.get('sign_longitude', {}).get('formatted', 'N/A')
        output_lines.append(f"  Position: {sign_long_fmt} {sign_name} ({sign_element}, {sign_modality})")
        output_lines.append(f"  Zodiac Longitude: {long_fmt}")

        house_info = obj.get('house', {})
        house_name = house_info.get('name', 'N/A')
        output_lines.append(f"  House: {house_name}")

        decan_info = obj.get('decan', {})
        decan_name = decan_info.get('name', 'N/A')
        output_lines.append(f"  Decan: {decan_name}")

        # Optional fields check
        if 'latitude' in obj:
            lat_fmt = obj['latitude'].get('formatted', 'N/A')
            output_lines.append(f"  Latitude: {lat_fmt}")
        
        decl_fmt = obj.get('declination', {}).get('formatted', 'N/A')
        output_lines.append(f"  Declination: {decl_fmt}" + (" (Out of Bounds)" if obj.get('out_of_bounds') else ""))

        if 'speed' in obj and 'movement' in obj:
            speed = obj.get('speed', 0.0)
            move_fmt = obj.get('movement', {}).get('formatted', 'N/A')
            output_lines.append(f"  Movement: {move_fmt} (Speed: {speed:.4f}°/day)") # Adjust precision as needed

        if 'distance' in obj:
            dist = obj.get('distance', 0.0)
            output_lines.append(f"  Distance: {dist:.4f} AU")

        if 'in_sect' in obj: # Only applies to traditional planets
            output_lines.append(f"  In Sect: {'Yes' if obj['in_sect'] else 'No'}")
            
        if 'dignities' in obj and obj['dignities'] and obj['dignities'].get('formatted'):
            dignities_str = ", ".join(obj['dignities']['formatted'])
            output_lines.append(f"  Dignities/Debilities: {dignities_str}")
            
        # Specific info for eclipses
        if obj_type == 'Eclipse':
             eclipse_type_info = obj.get('eclipse_type', {})
             eclipse_fmt = eclipse_type_info.get('formatted', 'N/A')
             eclipse_date_info = obj.get('date_time', {})
             eclipse_date = eclipse_date_info.get('datetime', 'N/A')
             output_lines.append(f"  Eclipse Type: {eclipse_fmt}")
             output_lines.append(f"  Eclipse Date: {eclipse_date}")


    output_lines.append("-" * 25) # Separator

    # --- 4. Houses ---
    output_lines.append("--- Houses (Cusps) ---")
    # Sort houses by number
    sorted_houses = sorted(chart_data['houses'].values(), key=lambda h: h['number'])
    
    for house in sorted_houses:
        house_name = house.get('name', 'Unknown House')
        output_lines.append(f"\n* {house_name} Cusp:")

        sign_info = house.get('sign', {})
        sign_name = sign_info.get('name', 'N/A')
        sign_element = sign_info.get('element', 'N/A')
        sign_modality = sign_info.get('modality', 'N/A')
        
        long_fmt = house.get('longitude', {}).get('formatted', 'N/A')
        sign_long_fmt = house.get('sign_longitude', {}).get('formatted', 'N/A')
        output_lines.append(f"  Position: {sign_long_fmt} {sign_name} ({sign_element}, {sign_modality})")
        output_lines.append(f"  Zodiac Longitude: {long_fmt}")
        
        size = house.get('size', 0.0)
        output_lines.append(f"  Size: {size:.2f}°") # Size of the house

    output_lines.append("-" * 25) # Separator

    # --- 5. Aspects ---
    output_lines.append("--- Aspects ---")
    processed_aspects = set() # To avoid printing duplicates like Sun-Moon and Moon-Sun

    # Iterate through all possible active objects that have aspects listed
    for active_id_str, passive_dict in chart_data.get('aspects', {}).items():
        # Iterate through all passive objects aspected by the active one
        for passive_id_str, aspect_details in passive_dict.items():
            
            # Create a unique identifier for the pair, regardless of order
            # Convert IDs to strings ensures consistent sorting if one is int and other str
            pair = tuple(sorted((active_id_str, passive_id_str))) 

            if pair in processed_aspects:
                continue # Skip if we've already processed this pair

            processed_aspects.add(pair) # Mark this pair as processed

            # Get object names from the map created earlier
            active_obj = object_map.get(active_id_str)
            passive_obj = object_map.get(passive_id_str)

            if not active_obj or not passive_obj:
                continue # Should not happen with valid data, but safety check

            active_name = active_obj.get('name', f'ID {active_id_str}')
            passive_name = passive_obj.get('name', f'ID {passive_id_str}')
            
            aspect_type = aspect_details.get('type', 'N/A')
            orb = aspect_details.get('orb', 0.0)
            diff_fmt = aspect_details.get('difference', {}).get('formatted', 'N/A')
            move_fmt = aspect_details.get('movement', {}).get('formatted', 'N/A')
            cond_fmt = aspect_details.get('condition', {}).get('formatted', 'N/A') # Associate/Dissociate

            # Format the aspect line
            # Example: Sun Conjunction Moon (Orb: 5.23°, Diff: +05°14'02", Applying, Associate)
            output_lines.append(
                f"* {active_name} {aspect_type} {passive_name} "
                f"(Orb: {orb:.2f}°, Diff: {diff_fmt}, {move_fmt}, {cond_fmt})"
            )

    if not processed_aspects:
         output_lines.append("  (No major aspects listed or calculable in source data)")
         
    output_lines.append("-" * 25) # Separator

    # --- 6. Weightings (Elements, Modalities, Quadrants) ---
    output_lines.append("--- Chart Weightings ---")
    weightings = chart_data.get('weightings', {})
    
    # Elements
    output_lines.append("\nElements:")
    elements = weightings.get('elements', {})
    for element, obj_list in elements.items():
        output_lines.append(f"  {element.capitalize()}: {len(obj_list)} objects")
        # Optionally list objects: ", ".join([object_map[str(oid)]['name'] for oid in obj_list])

    # Modalities
    output_lines.append("\nModalities:")
    modalities = weightings.get('modalities', {})
    for modality, obj_list in modalities.items():
         output_lines.append(f"  {modality.capitalize()}: {len(obj_list)} objects")

    # Quadrants
    output_lines.append("\nQuadrants (based on object count):")
    quadrants = weightings.get('quadrants', {})
    quadrant_names = { # Map keys to descriptive names
         'first': 'First (Houses 1-3)', 
         'second': 'Second (Houses 4-6)', 
         'third': 'Third (Houses 7-9)', 
         'fourth': 'Fourth (Houses 10-12)'
    }
    for quadrant_key, obj_list in quadrants.items():
         quad_name = quadrant_names.get(quadrant_key, quadrant_key.capitalize())
         output_lines.append(f"  {quad_name}: {len(obj_list)} objects")

    output_lines.append("-" * 25) # Separator
    output_lines.append("--- End of Transit Chart ---")

    return "\n".join(output_lines)

if __name__ == "__main__":
    location = (51.565131, -0.147709)
    
    transit_chart = get_transit_chart(location[0], location[1]  )
    with open("transit_chart.txt", "w") as f:
        f.write(transit_chart)
    
    print(f"Transit chart saved to transit_chart.txt")

File: 
utils/kerykeion_chart_utils.py
Content: 
import os
import json
from datetime import datetime
from pathlib import Path
from kerykeion import AstrologicalSubject, KerykeionChartSVG
from transit_reader.utils.screenshot_util import capture_svg_screenshot
from transit_reader.utils.constants import CHARTS_DIR

def get_kerykeion_subject(name: str, year: int, month: int, day: int, hour: int, minute: int, city: str, nation: str, longitude: float, latitude: float, timezone: str) -> AstrologicalSubject:
    subject = AstrologicalSubject(
        name,
        year,
        month,
        day,
        hour,
        minute,
        city=city,
        nation=nation,
        lng=longitude,
        lat=latitude,
        tz_str=timezone,
        online=False,
        disable_chiron_and_lilith=False
    )

    return subject

def get_kerykeion_transit_chart(subject: AstrologicalSubject, second_obj: AstrologicalSubject, new_output_directory: str) -> str:
    transit_chart = KerykeionChartSVG(
        subject,
        chart_type='Transit',
        second_obj=second_obj,
        new_output_directory=CHARTS_DIR,
        double_chart_aspect_grid_type='table'
    )

    transits_svg_file_path = f"{new_output_directory}/{subject.name} - Transit Chart.svg"
    transit_chart.makeSVG()
    if not os.path.exists(transits_svg_file_path):
        raise FileNotFoundError(f"SVG generation failed. {transits_svg_file_path} not found.")
    renamed_transits_svg_file_path = transits_svg_file_path.replace(" ", "_")
    os.rename(transits_svg_file_path, renamed_transits_svg_file_path)
    print(f"Renamed SVG file to: {renamed_transits_svg_file_path}")
    transit_chart_png = capture_svg_screenshot(renamed_transits_svg_file_path, new_output_directory)
    renamed_transit_chart_png = f"{new_output_directory}/{subject.name.replace(' ', '_')}_-_Transit_Chart.png"
    os.rename(transit_chart_png, renamed_transit_chart_png)
    print(f"Transit chart saved to: {renamed_transit_chart_png}")

    return renamed_transit_chart_png


if __name__ == "__main__":
    subject_data_file = Path(__file__).parent.parent / "subjects" / "benjamin_jasper.json"
    with open(subject_data_file, "r") as f:
        subject_data = json.load(f)
    
    name = subject_data["name"]
    dob = datetime.strptime(subject_data["date_of_birth"], "%Y-%m-%d %H:%M:%S")
    birth_longitude = subject_data["birthplace"]["longitude"]
    birth_latitude = subject_data["birthplace"]["latitude"]
    birthplace = subject_data["birthplace"]["place"]
    birthplace_country = subject_data["birthplace"]["country"]
    birthplace_timezone = subject_data["birthplace"]["timezone"]
    current_location_longitude = subject_data["current_location"]["longitude"]
    current_location_latitude = subject_data["current_location"]["latitude"]
    current_location = subject_data["current_location"]["place"]
    current_location_country = subject_data["current_location"]["country"]
    current_location_timezone = subject_data["current_location"]["timezone"]
    today = datetime.now()
    
    subject = get_kerykeion_subject(name, dob.year, dob.month, dob.day, dob.hour, dob.minute, birthplace, birthplace_country, birth_longitude, birth_latitude, birthplace_timezone)
    second_obj = get_kerykeion_subject("Here Now", today.year, today.month, today.day, today.hour, today.minute, current_location, current_location_country, current_location_longitude, current_location_latitude, current_location_timezone)
    get_kerykeion_transit_chart(subject, second_obj, CHARTS_DIR)


File: 
utils/models.py
Content: 
from pydantic import BaseModel, Field
from datetime import datetime
from transit_reader.utils.subject_selection import get_subject_data
from transit_reader.utils.constants import TODAY

subject_data = get_subject_data()

class TransitState(BaseModel):
    name: str = subject_data["name"]
    email: str = subject_data["email"]
    date_of_birth: datetime = datetime.strptime(subject_data["date_of_birth"], "%Y-%m-%d %H:%M:%S")
    dob: str = subject_data["date_of_birth"]
    birthplace: str = f"{subject_data['birthplace']['place']}, {subject_data['birthplace']['country']}"
    birthplace_city: str = subject_data["birthplace"]["place"]
    birthplace_country: str = subject_data["birthplace"]["country"]
    birthplace_latitude: float = subject_data["birthplace"]["latitude"]
    birthplace_longitude: float = subject_data["birthplace"]["longitude"]
    birthplace_timezone: str = subject_data["birthplace"]["timezone"]
    today: str = TODAY
    current_location: str = f"{subject_data['current_location']['place']}, {subject_data['current_location']['country']}"
    current_location_city: str = subject_data["current_location"]["place"]
    current_location_country: str = subject_data["current_location"]["country"]
    current_location_latitude: float = subject_data["current_location"]["latitude"]
    current_location_longitude: float = subject_data["current_location"]["longitude"]
    current_location_timezone: str = subject_data["current_location"]["timezone"]
    current_transits: str = ""
    transit_analysis: str = ""
    natal_chart: str = ""
    natal_analysis: str = ""
    transit_to_natal_chart: str = ""
    transit_to_natal_analysis: str = ""
    kerykeion_transit_chart: str = ""
    report_markdown: str = ""
    report_pdf: str = ""


class Email(BaseModel):
    subject: str = Field(description="The subject of the email.")
    body: str = Field(description="The body of the email.")


File: 
utils/qdrant_setup.py
Content: 
import os
import uuid
from pathlib import Path
from google import genai
from qdrant_client import QdrantClient
from qdrant_client.models import (
    PointStruct,
    Distance,
    VectorParams,
    Filter,
    FieldCondition,
    MatchValue,
)
from transit_reader.utils.constants import DOCS_DIR
import time


class Setup:
    def __init__(self, state):
        self.state = state
        # Initialize Gemini client
        self.gemini_api_key = os.environ.get("GEMINI_API_KEY")
        if self.gemini_api_key:
            # genai.configure(api_key=self.gemini_api_key)
            self.genai_client = genai.Client(api_key=self.gemini_api_key)
        else:
            print("⚠️ GEMINI_API_KEY not found in environment variables")
            self.genai_client = None

        # Initialize Qdrant client
        self.qdrant_url = os.environ.get("QDRANT_CLUSTER_URL")
        self.qdrant_api_key = os.environ.get("QDRANT_API_KEY")
        if self.qdrant_url and self.qdrant_api_key:
            self.qdrant_client = QdrantClient(
                url=self.qdrant_url, api_key=self.qdrant_api_key
            )
        else:
            print("⚠️ QDRANT_URL or QDRANT_API_KEY not found in environment variables")
            self.qdrant_client = None

        # Collection name for Qdrant
        self.collection_name = os.environ.get("QDRANT_COLLECTION_NAME")

        # Initialize QdrantVectorSearchTool to None (will be set up later if Qdrant setup is successful)
        self.qdrant_tool = None

        # Keep track of processed files to avoid duplicates
        self.processed_files = set()

    def process_new_markdown_files(self):
        """Find and process new markdown files in the astro_docs directory."""
        print("Checking for new markdown files...")

        md_files = list(DOCS_DIR.glob("*.md"))

        # Check which files are actually new by checking if they exist in Qdrant
        new_files = []
        for md_file in md_files:
            # Skip files we've already processed in this session
            if str(md_file) in self.processed_files:
                continue

            # Check if this file already exists in Qdrant
            if self.qdrant_client and self.qdrant_client.collection_exists(
                self.collection_name
            ):
                source_name = md_file.name
                try:
                    count_result = self.qdrant_client.count(
                        collection_name=self.collection_name,
                        count_filter=Filter(
                            must=[
                                FieldCondition(
                                    key="source",
                                    match=MatchValue(value=source_name),
                                )
                            ]
                        ),
                    )

                    if count_result.count > 0:
                        # File already exists in Qdrant, mark as processed
                        print(
                            f"File {source_name} already exists in Qdrant with {count_result.count} chunks"
                        )
                        self.processed_files.add(str(md_file))
                        continue
                except Exception as e:
                    print(f"Error checking if {source_name} exists in Qdrant: {e}")

            # If we got here, the file is new and needs processing
            new_files.append(md_file)

        if not new_files:
            print("No new markdown files found.")
            return 0

        print(f"Found {len(new_files)} new markdown files to process.")

        for file_path in new_files:
            try:
                # Extract text from the file
                file_path_obj, text_chunks = self.extract_text_from_markdown(
                    [file_path]
                )  # Pass as a list
                if not text_chunks:
                    print(f"⚠️ No text chunks extracted from {file_path}")
                    continue

                print(
                    f"Extracted {len(text_chunks)} chunks from {file_path_obj}"
                )  # Log filename early

                # Generate embeddings
                embeddings_with_text = self.generate_gemini_embeddings(text_chunks)
                if not embeddings_with_text:
                    print(f"⚠️ No embeddings generated for {file_path}")
                    continue

                # Store in Qdrant
                success = self.store_in_qdrant(embeddings_with_text)
                if success:
                    print(f"Successfully added {file_path} to Qdrant ✅")
                    self.processed_files.add(
                        str(file_path)
                    )  # Add the string representation
                else:
                    print(f"❌ Failed to add {file_path} to Qdrant")

            except Exception as e:
                print(f"❌ Error processing {file_path}: {e}")

        return len(new_files)


    def extract_text_from_markdown(self, md_files):
        """Extract text from markdown files in the astro_docs directory."""
        print("Extracting text from markdown files...")

        text_chunks = []

        if not md_files:
            print("⚠️ No markdown files provided")
            return (None, [])

        # We expect a *list* of Path objects, even if it's just one.
        if not isinstance(md_files, list) or not all(
            isinstance(f, Path) for f in md_files
        ):
            raise ValueError("md_files must be a list of Path objects")

        # Process only the specified file(s)
        for md_file in md_files:
            try:
                with open(md_file, "r", encoding="utf-8") as f:
                    content = f.read()

                    # Skip empty files
                    if not content.strip():
                        print(f"⚠️ Empty file: {md_file}")
                        continue

                    # Process the content into chunks with overlap
                    chunk_size = 1500
                    chunk_overlap = 250
                    current_position = 0
                    content_length = len(content)

                    while current_position < content_length:
                        end_position = min(
                            current_position + chunk_size, content_length
                        )

                        if end_position < content_length:
                            look_back_range = min(100, chunk_size // 10)
                            natural_break_pos = content.rfind(
                                "\n\n", end_position - look_back_range, end_position
                            )

                            if natural_break_pos != -1:
                                end_position = natural_break_pos
                            else:
                                for punct in [". ", "! ", "? ", "\n"]:
                                    natural_break_pos = content.rfind(
                                        punct,
                                        end_position - look_back_range,
                                        end_position,
                                    )
                                    if natural_break_pos != -1:
                                        end_position = natural_break_pos + 1
                                        break

                        chunk = content[current_position:end_position].strip()

                        if chunk:
                            text_chunks.append(
                                {
                                    "text": chunk,
                                    "source": md_file.name,  # Keep using .name for consistency
                                }
                            )

                        current_position = (
                            end_position - chunk_overlap
                            if end_position < content_length
                            else content_length
                        )

            except Exception as e:
                print(f"❌ Error reading {md_file}: {e}")
                # Return (None, []) on error to signal failure for this file
                return (None, [])

        # Return the *Path object* and the chunks.
        return (md_files[0], text_chunks)

    def generate_gemini_embeddings(self, text_chunks):
        """Generate embeddings for text chunks using Gemini API."""
        print("Generating Gemini embeddings...")

        if not self.genai_client:
            print("❌ Gemini client not initialized. Cannot generate embeddings.")
            return []

        embeddings_with_text = []
        failed_chunks = 0
        batch_size = 10  # Process in batches to avoid overwhelming the API
        requests_per_minute = 150
        delay_between_requests = (
            60.0 / requests_per_minute
        )  # Calculate delay in seconds

        for i in range(0, len(text_chunks), batch_size):
            batch = text_chunks[i : i + batch_size]
            print(
                f"Processing batch {i // batch_size + 1}/{(len(text_chunks) + batch_size - 1) // batch_size}...",
                end="\r",
            )

            for chunk in batch:
                try:
                    # Generate embedding using Gemini
                    result = self.genai_client.models.embed_content(
                        model="text-embedding-004", contents=chunk["text"]
                    )

                    # Correctly access the embedding values
                    embedding_values = result.embeddings[
                        0
                    ].values  # Access the first embedding and its values

                    # Add embedding to the chunk data
                    embeddings_with_text.append(
                        {
                            "text": chunk["text"],
                            "source": chunk["source"],
                            "embedding": embedding_values,
                        }
                    )
                    time.sleep(delay_between_requests)  # delay
                except Exception as e:
                    failed_chunks += 1
                    print(
                        f"❌ Error generating embedding for chunk from {chunk['source']}: {e}"
                    )
                    # Continue processing other chunks despite this error

        if failed_chunks > 0:
            print(
                f"⚠️ Failed to generate embeddings for {failed_chunks} chunks out of {len(text_chunks)}"
            )

        print(f"Generated {len(embeddings_with_text)} embeddings ✅")
        return embeddings_with_text

    def store_in_qdrant(self, embeddings_with_text):
        """Store text and embeddings in Qdrant."""
        print(f"Storing embeddings in Qdrant collection '{self.collection_name}'...")

        if not self.qdrant_client:
            print("❌ Qdrant client not initialized. Cannot store embeddings.")
            return False

        try:
            # Check if collection exists and has correct vector size
            vector_size = 768  # Gemini text-embedding-004 has 768 dimensions

            if self.qdrant_client.collection_exists(self.collection_name):
                try:
                    collection_info = self.qdrant_client.get_collection(
                        self.collection_name
                    )
                    existing_vector_size = collection_info.config.params.vectors.size

                    if existing_vector_size != vector_size:
                        print(
                            f"Collection '{self.collection_name}' exists but with incorrect vector size ({existing_vector_size}). Recreating with size {vector_size}."
                        )
                        self.qdrant_client.delete_collection(self.collection_name)
                        create_collection = True
                    else:
                        print(
                            f"Collection '{self.collection_name}' already exists with correct vector size. Updating points."
                        )
                        create_collection = False
                except Exception as e:
                    print(f"❌ Error checking collection info: {e}")
                    print(f"Recreating collection '{self.collection_name}'.")
                    self.qdrant_client.delete_collection(self.collection_name)
                    create_collection = True
            else:
                print(
                    f"Collection '{self.collection_name}' does not exist. Creating it."
                )
                create_collection = True

            # Create collection if needed
            if create_collection:
                self.qdrant_client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(
                        size=vector_size, distance=Distance.COSINE
                    ),
                )

            # Prepare points for Qdrant
            points = []
            for item in embeddings_with_text:
                points.append(
                    PointStruct(
                        id=str(uuid.uuid4()),
                        vector=item["embedding"],
                        payload={"text": item["text"], "source": item["source"]},
                    )
                )

            # Upload points to Qdrant in batches
            if points:
                batch_size = 100  # Adjust based on your needs
                for i in range(0, len(points), batch_size):
                    batch = points[i : i + batch_size]
                    print(
                        f"Uploading batch {i // batch_size + 1}/{(len(points) + batch_size - 1) // batch_size} to Qdrant...",
                        end="\r",
                    )
                    self.qdrant_client.upsert(
                        collection_name=self.collection_name, points=batch
                    )
                print(f"Successfully stored {len(points)} points in Qdrant ✅")
                return True
            else:
                print("⚠️ No points to store in Qdrant")
                return False

        except Exception as e:
            print(f"❌ Error storing embeddings in Qdrant: {e}")
            print(f"Error details: {str(e)}")  # More detailed error information
            return False


File: 
utils/screenshot_util.py
Content: 
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
import os
from pathlib import Path
from contextlib import contextmanager
from datetime import datetime

# Constants
CHROME_BINARY_PATH = "/usr/bin/chromium-browser"
CHROMEDRIVER_PATH = "/usr/local/bin/chromedriver"

@contextmanager
def get_driver(window_size=(1920, 1080)):
    """Context manager for handling driver creation and cleanup"""
    chrome_options = Options()
    chrome_options.binary_location = CHROME_BINARY_PATH
    
    # Core options
    chrome_options.add_argument('--headless=new')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--remote-debugging-pipe')
    chrome_options.add_argument('--disable-gpu')
    
    # Additional stability options
    chrome_options.add_argument('--disable-extensions')
    chrome_options.add_argument('--disable-software-rasterizer')
    chrome_options.add_argument('--disable-features=VizDisplayCompositor')
    
    # Create a temporary directory for Chrome
    tmp_dir = '/tmp/chrome-data'
    os.makedirs(tmp_dir, exist_ok=True)
    chrome_options.add_argument(f'--user-data-dir={tmp_dir}')
    
    service = Service(
        executable_path=CHROMEDRIVER_PATH,
        service_args=['--verbose', '--log-path=/tmp/chromedriver.log']
    )
    
    driver = None
    try:
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.set_window_size(*window_size)
        yield driver
    finally:
        if driver:
            try:
                driver.close()
                driver.quit()
            except Exception as e:
                print(f"Error during driver cleanup: {e}")
            try:
                import shutil
                shutil.rmtree(tmp_dir, ignore_errors=True)
            except Exception as e:
                print(f"Error cleaning up temp directory: {e}")


def capture_svg_screenshot(svg_path: str, output_dir: str = "./screenshots") -> str:
    """
    Opens an SVG file in a headless browser, takes a screenshot, and saves it.

    Args:
        svg_path (str): The file path to the SVG file.
        output_dir (str): Directory to save the screenshot. Defaults to "./screenshots".

    Returns:
        str: The file path of the saved screenshot.
    """
    # Validate the SVG file path
    if not os.path.exists(svg_path):
        raise FileNotFoundError(f"SVG file not found: {svg_path}")

    # Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Generate the screenshot file path
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    screenshot_path = os.path.join(output_dir, f"svg_screenshot_{timestamp}.png")

    try:
        with get_driver() as driver:
            # Set higher DPR for better resolution
            driver.execute_cdp_cmd('Emulation.setDeviceMetricsOverride', {
                'mobile': False,
                'width': 1920,
                'height': 1080,
                'deviceScaleFactor': 2.0  # This doubles the resolution
            })

            # Open the SVG file
            driver.get(f"file://{os.path.abspath(svg_path)}")

            # Wait for SVG to load and get its dimensions
            script = """
                return {
                    width: document.documentElement.getBoundingClientRect().width,
                    height: document.documentElement.getBoundingClientRect().height
                };
            """
            dimensions = driver.execute_script(script)
            
            # Set window size to match SVG dimensions with the scaling factor
            driver.set_window_size(
                int(dimensions['width'] * 2) + 40,  # Double the width + padding
                int(dimensions['height'] * 2) + 40  # Double the height + padding
            )

            # Save the screenshot
            driver.save_screenshot(screenshot_path)
            print(f"Screenshot saved to: {screenshot_path}")
    except Exception as e:
        raise RuntimeError(f"Failed to capture SVG screenshot: {e}")

    return screenshot_path

if __name__ == "__main__":
    capture_svg_screenshot("/home/j/ai/crewAI/astro/transit_reader/output/2025-04-08/Benjamin_Jasper_-_Transit_Chart.svg")


File: 
utils/subject_selection.py
Content: 
import json
import os
import googlemaps
from transit_reader.utils.constants import SUBJECT_DIR
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

# ANSI color codes
RED = "\033[91m"
RESET = "\033[0m" 

gmaps = googlemaps.Client(key=os.getenv("GMAPS_API_KEY"))

# Helper function to format display name from filename
def _format_display_name(filename):
    name_part = filename.stem
    return ' '.join(word.capitalize() for word in name_part.split('_'))

def get_date_of_birth():
    while True:
        try:
            year = int(input("Enter the year of birth: "))
            if year < 0 or year > datetime.now().year:
                raise ValueError
            break
        except ValueError:
            # Format error message in red
            print(f"{RED}Invalid year. Please enter a valid year between 0 and {datetime.now().year}.{RESET}")

    while True:
        try:
            month = int(input("Enter the month of birth (1-12): "))
            if month < 1 or month > 12:
                raise ValueError
            break
        except ValueError:
            # Format error message in red
            print(f"{RED}Invalid month. Please enter a valid month between 1 and 12.{RESET}")

    while True:
        try:
            day = int(input("Enter the day of birth (1-31): "))
            # Simplified date validation logic
            try:
                # Check if the date is valid for the given month/year
                datetime(year, month, day) 
            except ValueError as e:
                 # Format error message in red
                print(f"{RED}Invalid day: {e}. Please enter a valid day.{RESET}")
                continue # Ask again
            break # Exit loop if date is valid
        except ValueError: # Catch potential int conversion errors
             # Format error message in red
            print(f"{RED}Invalid input. Please enter a number for the day.{RESET}")
            
    return year, month, day
    

def get_time_of_birth():
    while True:
        try:
            time = input("Enter the time of birth in 24-hour format (e.g. 15:30 for 3:30pm): ")
            hour, minute = map(int, time.split(':'))
            if hour < 0 or hour > 23:
                raise ValueError
            if minute < 0 or minute > 59:
                raise ValueError
            break
        except ValueError:
             # Format error message in red
            print(f"{RED}Invalid time. Please enter a valid time in 24-hour format (e.g. 15:30 for 3:30pm).{RESET}")

    return hour, minute


def get_timezone(latitude, longitude):
    timestamp = datetime.now().timestamp()
    try:
        timezone_result = gmaps.timezone((latitude, longitude), timestamp=timestamp)
        if timezone_result and 'timeZoneId' in timezone_result:
            timezone_str = timezone_result['timeZoneId']
        else:
             # Format warning message in red (optional, could be yellow/normal)
            print(f"{RED}Warning: Could not determine timezone via Google API.{RESET}")
            timezone_str = None
    except Exception as e:
        # Format error message in red
        print(f"{RED}Error getting timezone from Google API: {e}{RESET}")
        timezone_str = None # Or ask user? For now, setting to None.
    return timezone_str


def get_place_of_birth():
    while True:
        try:
            address = input("Enter the place of birth: ")
            geocode_result = gmaps.geocode(address)
            if not geocode_result:
                 # Format error message in red
                print(f"{RED}Invalid address. Could not geocode. Please enter a valid address.{RESET}")
                continue

            # Defensive coding: check structure before accessing
            if not isinstance(geocode_result, list) or len(geocode_result) == 0:
                 print(f"{RED}Unexpected geocode result format. Please try again.{RESET}")
                 continue
                 
            location = geocode_result[0].get('geometry', {}).get('location', {})
            if not location or 'lat' not in location or 'lng' not in location:
                 # Format error message in red
                print(f"{RED}Could not get coordinates for this address. Please try again.{RESET}")
                continue

            address_components = geocode_result[0].get('address_components', [])
            city = next((comp['long_name'] for comp in address_components if 'locality' in comp['types']), None)
            country = next((comp['long_name'] for comp in address_components if 'country' in comp['types']), None)

            # Handle cases where city or country might not be found
            if not city:
                print("Could not determine city from address components. Using address as fallback.")
                # Attempt to get a broader administrative area or use the formatted address
                city = next((comp['long_name'] for comp in address_components if 'administrative_area_level_1' in comp['types']), None)
                if not city:
                     city = geocode_result[0].get('formatted_address', address) # Fallback

            if not country:
                 print("Could not determine country from address components.")
                 # Maybe add a fallback or raise an error depending on requirements
                 country = "Unknown" # Placeholder

            return city, country, location['lat'], location['lng']
        except googlemaps.exceptions.ApiError as e:
             print(f"{RED}Google Maps API Error: {e}. Check API key and usage limits.{RESET}")
             # Decide if to retry or exit. For now, retrying.
        except Exception as e:
             # Format error message in red
            print(f"{RED}Error processing place of birth: {e}. Please try again.{RESET}")


def get_subject_data(subject_name=None):
    SUBJECT_DIR.mkdir(parents=True, exist_ok=True) # Ensure directory exists
    
    existing_subjects = list(SUBJECT_DIR.glob('*.json'))
    subject_map = {i + 1: subject_file for i, subject_file in enumerate(existing_subjects)}

    selected_subject_file = None

    if subject_map:
        print("Existing subjects:")
        for num, file_path in subject_map.items():
            display_name = _format_display_name(file_path)
            print(f"  {num} - {display_name}")
        
        prompt = "Enter the number of an existing subject, or enter a new name to create: "
    else:
        prompt = "No existing subjects found. Enter a name to create a new subject: "

    while True: # Loop until valid selection or new name
        user_input = input(prompt).strip()
        if user_input.isdigit():
            try:
                selection_num = int(user_input)
                if selection_num in subject_map:
                    selected_subject_file = subject_map[selection_num]
                    subject_name = _format_display_name(selected_subject_file) # Use formatted name
                    print(f"Selected existing subject: {subject_name}")
                    break 
                else:
                     # Format error message in red
                    print(f"{RED}Invalid number. Please select from the list.{RESET}")
            except ValueError:
                 # Format error message in red
                 # This case might not be reached due to isdigit(), but good practice
                print(f"{RED}Invalid input. Please enter a number or a name.{RESET}")
        elif user_input: # Treat as a new name
            subject_name = user_input
            subject_name_formatted = subject_name.lower().replace(" ", "_")
            selected_subject_file = SUBJECT_DIR / f"{subject_name_formatted}.json"
            if selected_subject_file.exists():
                 # Format error message in red
                print(f"{RED}A subject with this name ('{subject_name_formatted}.json') already exists. Please choose a different name or select the existing entry by number if listed.{RESET}")
                # Re-prompt by continuing the loop
            else:
                print(f"Creating new subject: {subject_name}")
                # Pass formatted name for file, original for display/data
                create_subject_data(subject_name_formatted, subject_name) 
                break # Exit loop after creation attempt
        else:
             # Format error message in red
             print(f"{RED}Input cannot be empty. Please enter a number or a name.{RESET}")


    # Load data from the selected or newly created file
    if selected_subject_file and selected_subject_file.exists():
        try:
            with open(selected_subject_file, 'r') as f:
                subject_data = json.load(f)
            return subject_data
        except json.JSONDecodeError:
             # Format error message in red
            print(f"{RED}Error: The subject file {selected_subject_file} is corrupted or not valid JSON.{RESET}")
            return None
        except Exception as e: # Catch other potential file reading errors
            print(f"{RED}Error reading subject file {selected_subject_file}: {e}{RESET}")
            return None
    else:
         # Format error message in red
         # This path might be reached if create_subject_data failed to write the file
        print(f"{RED}Error: Could not find or load the subject file: {selected_subject_file}{RESET}")
        return None


def create_subject_data(subject_file_name, original_name):
    print(f"\n--- Creating data for {original_name} ---")
    year, month, day = get_date_of_birth()
    hour, minute = get_time_of_birth()
    # Handle potential errors from get_place_of_birth if it returns None or raises exception
    try:
        place_info = get_place_of_birth()
        if place_info is None:
             print(f"{RED}Failed to get place of birth information. Aborting subject creation.{RESET}")
             return # Stop creation if place info is missing
        city, country, lat, lon = place_info
    except Exception as e:
        print(f"{RED}An unexpected error occurred during place of birth entry: {e}. Aborting subject creation.{RESET}")
        return

    timezone = get_timezone(lat, lon)

    # Ask for email (optional)
    email = input("Enter email address (optional, press Enter to skip): ").strip()

    dob_datetime = datetime(year, month, day, hour, minute)
    dob_str = dob_datetime.strftime("%Y-%m-%d %H:%M:%S")

    subject_data = {
        "name": original_name,
        "date_of_birth": dob_str,
        "birthplace": {
            "longitude": lon,
            "latitude": lat,
            "place": city,
            "country": country,
            "timezone": timezone # Timezone can be None if lookup failed
        }
    }
    
    # Add email only if provided
    if email:
        subject_data["email"] = email

    # Ensure the SUBJECT_DIR exists (redundant check, but safe)
    SUBJECT_DIR.mkdir(parents=True, exist_ok=True) 
    
    SUBJECT_FILE = SUBJECT_DIR / f"{subject_file_name}.json"
    try:
        with open(SUBJECT_FILE, 'w') as f:
            json.dump(subject_data, f, indent=4)
        print(f"Subject data saved successfully to {SUBJECT_FILE}")
    except IOError as e:
         # Format error message in red
        print(f"{RED}Error writing subject data to file {SUBJECT_FILE}: {e}{RESET}")



if __name__ == "__main__":
    # Removed the empty string argument, get_subject_data now handles the prompting
    subject_data = get_subject_data() 
    if subject_data:
        print("\n--- Loaded Subject Data ---")
        print(json.dumps(subject_data, indent=4))
    else:
        print("\nFailed to load or create subject data.")





